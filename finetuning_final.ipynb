{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í•œêµ­ì–´ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ - ìµœì í™”ëœ íŒŒì¸íŠœë‹\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ WandB Sweepì„ í†µí•´ ì°¾ì€ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•œ íŒŒì¸íŠœë‹\n",
    "- DAPT (Domain-Adapted Pre-Training) ëª¨ë¸ ì‚¬ìš©\n",
    "- ë°ì´í„°ì…‹ ë¹„ìœ¨ ì¡°ì •: original(1.0) : augment(3.0)\n",
    "- ëª¨ë¸ ì €ì¥ ë° í‰ê°€\n",
    "- WandBë¥¼ í†µí•œ ì‹¤í—˜ ì¶”ì \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# PEFT for LoRA\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ë°”ì´ìŠ¤: cuda\n",
      "GPU ê°œìˆ˜: 1\n",
      "   GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ì´ í•¨ìˆ˜ê°€ .env íŒŒì¼ì„ ì½ì–´ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í›ˆë ¨ ì§„í–‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# ê³ ì • ì„¤ì •\n",
    "PROJECT_NAME = \"[domain_project]_Final_Training_original\"\n",
    "MODEL_NAME = \"TAPT_klue_Roberta-kor-base_final_training_2025-10-30_00-40-22_RANDOM_42\"\n",
    "RUN_NAME = f\"{MODEL_NAME}_final_training_{TIMESTAMP}_RANDOM_{RANDOM_STATE}\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ\n",
      "learning_rate: 1.00e-05\n",
      "batch_size: 400\n",
      "label_smoothing_factor: 0.120\n",
      "weight_decay: 0.040\n",
      "num_epochs: 4\n",
      "augment_ratio: 0.0\n",
      "ëª¨ë¸ ì €ì¥ ê²½ë¡œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Sweep ê²°ê³¼ ê¸°ë°˜)\n",
    "class OptimalConfig:\n",
    "    # ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° (Sweepì—ì„œ ì°¾ì€ ìµœê³  ì„±ëŠ¥)\n",
    "    learning_rate = 1e-05  \n",
    "    batch_size = 400\n",
    "    label_smoothing_factor = 0.12  \n",
    "    weight_decay = 0.04  \n",
    "    num_epochs = 4\n",
    "    augment_ratio = 0.0  # original ëŒ€ë¹„ 3ë°°\n",
    "\n",
    "    \n",
    "    # ë°ì´í„°ì…‹ ë¹„ìœ¨ ì„¤ì •\n",
    "    original_ratio = 1.0  # í•­ìƒ 1.0 (ê¸°ì¤€)\n",
    "    \n",
    "    # ê¸°íƒ€ ì„¤ì •\n",
    "    warmup_steps = 10\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1.0\n",
    "    early_stopping_patience = 2\n",
    "    save_best_model = True  # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ\n",
    "    save_model_path = f\"./Final_Models/original/{RUN_NAME}\"\n",
    "    \n",
    "    # WandB ì„¤ì •\n",
    "    use_wandb = True\n",
    "    project_name = PROJECT_NAME\n",
    "\n",
    "optimal_config = OptimalConfig()\n",
    "\n",
    "print(\"âœ… ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"learning_rate: {optimal_config.learning_rate:.2e}\")\n",
    "print(f\"batch_size: {optimal_config.batch_size}\")\n",
    "print(f\"label_smoothing_factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "print(f\"weight_decay: {optimal_config.weight_decay:.3f}\")\n",
    "print(f\"num_epochs: {optimal_config.num_epochs}\")\n",
    "print(f\"augment_ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê³ ì • ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê³ ì • ì„¤ì •\n",
    "class FixedConfig:\n",
    "    # ëª¨ë¸ ì„¤ì •\n",
    "    model_name = MODEL_NAME\n",
    "    base_models_path = \"\"\n",
    "    local_model_path = base_models_path + MODEL_NAME\n",
    "\n",
    "    is_DAPT = True\n",
    "    DAPT_model_path = f\"/data/ephemeral/home/code/Final_Models/{MODEL_NAME}\"\n",
    "    \n",
    "    num_classes = 4\n",
    "    max_length = 128\n",
    "\n",
    "    # ë°ì´í„° ì„¤ì •\n",
    "    train_data_path = \"/data/ephemeral/home/code/data/train_final_augX3.csv\"\n",
    "    val_data_path = \"/data/ephemeral/home/code/data/val_final.csv\"\n",
    "    \n",
    "    # ê³ ì • í›ˆë ¨ ì„¤ì •\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loss ì„¤ì •\n",
    "    loss_function = \"CrossEntropy\"\n",
    "    use_label_smoothing = True\n",
    "    use_lora = False\n",
    "\n",
    "fixed_config = FixedConfig()\n",
    "print(\"âœ… ê³ ì • ì„¤ì • ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ë¹„ìœ¨ì— ë”°ë¥¸ ìƒ˜í”Œë§ í•¨ìˆ˜\n",
    "def sample_dataset_by_ratio(df, augment_ratio=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°ì…‹ì„ ë¹„ìœ¨ì— ë”°ë¼ ìƒ˜í”Œë§í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        df: ì „ì²´ ë°ì´í„°í”„ë ˆì„\n",
    "        augment_ratio: augment ë°ì´í„° ë¹„ìœ¨ (original ëŒ€ë¹„)\n",
    "        random_state: ëœë¤ ì‹œë“œ\n",
    "    \n",
    "    Returns:\n",
    "        sampled_df: ìƒ˜í”Œë§ëœ ë°ì´í„°í”„ë ˆì„\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # ê° íƒ€ì…ë³„ ë°ì´í„° ë¶„ë¦¬\n",
    "    original_data = df[df['type'] == 'original'].copy()\n",
    "    augment_data = df[df['type'] == 'augment'].copy()\n",
    "    \n",
    "    print(f\"ì›ë³¸ ë°ì´í„° ë¶„í¬:\")\n",
    "    print(f\"  Original: {len(original_data):,}ê°œ\")\n",
    "    print(f\"  Augment: {len(augment_data):,}ê°œ\")\n",
    "    \n",
    "    # Original ë°ì´í„°ëŠ” í•­ìƒ 100% ì‚¬ìš©\n",
    "    sampled_original = original_data.copy()\n",
    "    \n",
    "    # Augment ë°ì´í„° ìƒ˜í”Œë§\n",
    "    if augment_ratio > 0 and len(augment_data) > 0:\n",
    "        # original ëŒ€ë¹„ ë¹„ìœ¨ë¡œ ìƒ˜í”Œë§\n",
    "        target_augment_size = int(len(original_data) * augment_ratio)\n",
    "        if target_augment_size > len(augment_data):\n",
    "            # ìš”ì²­ëœ í¬ê¸°ê°€ ì „ì²´ë³´ë‹¤ í¬ë©´ ì „ì²´ ì‚¬ìš©\n",
    "            sampled_augment = augment_data.copy()\n",
    "        else:\n",
    "            # ë¹„ìœ¨ì— ë§ê²Œ ìƒ˜í”Œë§\n",
    "            sampled_augment = augment_data.sample(n=target_augment_size, random_state=random_state)\n",
    "    else:\n",
    "        sampled_augment = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    \n",
    "    # ìƒ˜í”Œë§ëœ ë°ì´í„° í•©ì¹˜ê¸°\n",
    "    sampled_df = pd.concat([sampled_original, sampled_augment], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\\\nìƒ˜í”Œë§ëœ ë°ì´í„° ë¶„í¬:\")\n",
    "    print(f\"  Original: {len(sampled_original):,}ê°œ (ë¹„ìœ¨: 1.0)\")\n",
    "    print(f\"  Augment: {len(sampled_augment):,}ê°œ (ë¹„ìœ¨: {augment_ratio:.1f})\")\n",
    "    print(f\"  ì´ ë°ì´í„°: {len(sampled_df):,}ê°œ\")\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "ì „ì²´ ë°ì´í„°: 536,966ê°œ\n",
      "ê²€ì¦ ë°ì´í„°: 6,823ê°œ\n",
      "ì „ì²´ ë°ì´í„°: 543,789ê°œ\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„° ë¡œë“œ (ë¹„ìœ¨ ìƒ˜í”Œë§ì„ ìœ„í•´)\n",
    "print(\"ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ì›ë³¸ ë°ì´í„° ë¡œë“œ (preprocessing_final.ipynbì—ì„œ ìƒì„±ëœ ë°ì´í„°)\n",
    "full_df = pd.read_csv(fixed_config.train_data_path)\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(full_df):,}ê°œ\")\n",
    "\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„° ë¡œë“œ (originalë§Œ ì‚¬ìš©)\n",
    "val_df = pd.read_csv(fixed_config.val_data_path)\n",
    "\n",
    "full_df = pd.concat([full_df, val_df], ignore_index=True)\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_df):,}ê°œ\")\n",
    "print(f\"ì „ì²´ ë°ì´í„°: {len(full_df):,}ê°œ\")\n",
    "print(\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ë¦¬ë·° í…ìŠ¤íŠ¸ ë°ì´ì…‹ í´ë˜ìŠ¤\n",
    "    - BERT ëª¨ë¸ í›ˆë ¨/ì¶”ë¡ ì„ ìœ„í•œ PyTorch Dataset êµ¬í˜„\n",
    "    - í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§• ë° í…ì„œ ë³€í™˜ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        ë°ì´í„°ì…‹ ì´ˆê¸°í™”\n",
    "        \"\"\"\n",
    "        self.texts, self.labels, self.tokenizer, self.max_length = (\n",
    "            texts,\n",
    "            labels,\n",
    "            tokenizer,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"ë°ì´í„°ì…‹ í¬ê¸° ë°˜í™˜\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë°ì´í„° ì•„ì´í…œ ë°˜í™˜\n",
    "        \"\"\"\n",
    "        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§• ë° íŒ¨ë”©\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,  # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ìë¥´ê¸°\n",
    "            padding=\"max_length\",  # ìµœëŒ€ ê¸¸ì´ê¹Œì§€ íŒ¨ë”©\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",  # PyTorch í…ì„œë¡œ ë°˜í™˜\n",
    "        )\n",
    "\n",
    "        # ê¸°ë³¸ ì•„ì´í…œ êµ¬ì„± (input_ids, attention_mask)\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        # labelsê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€ (train/validìš©)\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜\n",
    "def compute_metrics(predictions, labels):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    # ì˜ˆì¸¡ê°’ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "print(\"âœ… í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_from_local(local_model_path : str = None, model_name : str = None):\n",
    "    # 1. í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    # ì ˆëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\")\n",
    "\n",
    "    # ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if not os.path.exists(local_model_path):\n",
    "        print(f\"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {local_model_path}\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(f\"âœ… ê²½ë¡œ í™•ì¸ë¨: {local_model_path}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "    # 2. ëª¨ë¸ ë¡œë“œ\n",
    "    # ë§ˆì°¬ê°€ì§€ë¡œ ë¡œì»¬ ê²½ë¡œ(local_model_path)ë¥¼ ì‚¬ìš©\n",
    "    print(\"ë¡œì»¬ ê²½ë¡œì—ì„œ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        local_model_path,\n",
    "        num_labels=4,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    print(\"âœ… ë¡œì»¬ ìŠ¤ëƒ…ìƒ·ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”© ì„±ê³µ!\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label Smoothing í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def label_smoothing_cross_entropy(predictions, targets, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    predictions: ëª¨ë¸ ì¶œë ¥ (logits) [batch_size, num_classes]\n",
    "    targets: ì •ë‹µ ë¼ë²¨ (ì •ìˆ˜) [batch_size]\n",
    "    smoothing: smoothing factor\n",
    "    \"\"\"\n",
    "    num_classes = predictions.size(-1)\n",
    "    \n",
    "    # í•˜ë“œ ë¼ë²¨ì„ ì›-í•«ìœ¼ë¡œ ë³€í™˜\n",
    "    true_dist = torch.zeros_like(predictions)\n",
    "    true_dist.fill_(smoothing / (num_classes - 1))\n",
    "    true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - smoothing)\n",
    "    \n",
    "    # KL divergence = Cross Entropy with smoothed labels\n",
    "    return F.kl_div(F.log_softmax(predictions, dim=1), true_dist, reduction='batchmean')\n",
    "\n",
    "print(\"âœ… Label Smoothing í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, scaler, device, config, criterion_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # í˜¼í•© ì •ë°€ë„ í›ˆë ¨\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "                logits = outputs.logits\n",
    "                loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
    "        \n",
    "        # ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "        predictions.extend(logits.detach().cpu().numpy())\n",
    "        labels.extend(batch_labels.detach().cpu().numpy())\n",
    "        \n",
    "        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item() * config.gradient_accumulation_steps:.4f}',\n",
    "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ê²€ì¦ í•¨ìˆ˜\n",
    "def validate_epoch(model, dataloader, device, criterion_fn):\n",
    "    \"\"\"í•œ ì—í¬í¬ ê²€ì¦\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # ìˆœì „íŒŒ\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            loss = criterion_fn(logits, batch_labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "            predictions.extend(logits.detach().cpu().numpy())\n",
    "            labels.extend(batch_labels.detach().cpu().numpy())\n",
    "            \n",
    "            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"âœ… ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… í›ˆë ¨ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì €ì¥ í•¨ìˆ˜\n",
    "def save_model(model, tokenizer, save_path, epoch, val_accuracy):\n",
    "    \"\"\"ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "    # ì„¤ì • ì •ë³´ ì €ì¥\n",
    "    config_info = {\n",
    "        \"epoch\": epoch,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"timestamp\": TIMESTAMP,\n",
    "        \"model_name\": fixed_config.model_name,\n",
    "        \"learning_rate\": optimal_config.learning_rate,\n",
    "        \"batch_size\": optimal_config.batch_size,\n",
    "        \"label_smoothing_factor\": optimal_config.label_smoothing_factor,\n",
    "        \"weight_decay\": optimal_config.weight_decay,\n",
    "        \"augment_ratio\": optimal_config.augment_ratio,\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(save_path, \"training_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "    print(f\"   Epoch: {epoch}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜\n",
    "def train_final_model():\n",
    "    # WandB ì´ˆê¸°í™”\n",
    "    if optimal_config.use_wandb:\n",
    "        run = wandb.init(\n",
    "            project=optimal_config.project_name,\n",
    "            name=RUN_NAME,\n",
    "            config={\n",
    "                \"learning_rate\": optimal_config.learning_rate,\n",
    "                \"batch_size\": optimal_config.batch_size,\n",
    "                \"label_smoothing_factor\": optimal_config.label_smoothing_factor,\n",
    "                \"weight_decay\": optimal_config.weight_decay,\n",
    "                \"num_epochs\": optimal_config.num_epochs,\n",
    "                \"augment_ratio\": optimal_config.augment_ratio,\n",
    "                \"model_name\": fixed_config.model_name,\n",
    "                \"is_DAPT\": fixed_config.is_DAPT\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì‹œì‘\")\n",
    "    print(f\"learning_rate: {optimal_config.learning_rate:.2e}\")\n",
    "    print(f\"batch_size: {optimal_config.batch_size}\")\n",
    "    print(f\"label_smoothing_factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "    print(f\"weight_decay: {optimal_config.weight_decay:.3f}\")\n",
    "    print(f\"num_epochs: {optimal_config.num_epochs}\")\n",
    "    print(f\"augment_ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "    print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {optimal_config.save_model_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "        if fixed_config.is_DAPT:\n",
    "            model, tokenizer = model_load_from_local(fixed_config.DAPT_model_path, fixed_config.model_name)\n",
    "        else:\n",
    "            model, tokenizer = model_load_from_local(fixed_config.local_model_path, fixed_config.model_name)\n",
    "        \n",
    "        if model is None or tokenizer is None:\n",
    "            print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            return\n",
    "        \n",
    "        model = model.to(fixed_config.device)\n",
    "        \n",
    "        # ë¹„ìœ¨ì— ë”°ë¼ í›ˆë ¨ ë°ì´í„° ìƒ˜í”Œë§\n",
    "        print(\"\\në°ì´í„°ì…‹ ë¹„ìœ¨ì— ë”°ë¥¸ ìƒ˜í”Œë§ ì¤‘...\")\n",
    "        train_df_sampled = sample_dataset_by_ratio(\n",
    "            full_df, \n",
    "            augment_ratio=optimal_config.augment_ratio, \n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "        train_dataset = ReviewDataset(\n",
    "            train_df_sampled[\"review\"],\n",
    "            train_df_sampled[\"label\"],\n",
    "            tokenizer,\n",
    "            fixed_config.max_length,\n",
    "        )\n",
    "\n",
    "        val_dataset = ReviewDataset(\n",
    "            val_df[\"review\"],\n",
    "            val_df[\"label\"],\n",
    "            tokenizer,\n",
    "            fixed_config.max_length,\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=optimal_config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=optimal_config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        \n",
    "        # ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •\n",
    "        def criterion_fn(predictions, targets):\n",
    "            return label_smoothing_cross_entropy(predictions, targets, optimal_config.label_smoothing_factor)\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=optimal_config.learning_rate,\n",
    "            weight_decay=optimal_config.weight_decay\n",
    "        )\n",
    "\n",
    "        # ì „ì²´ í›ˆë ¨ ìŠ¤í… ê³„ì‚°\n",
    "        total_steps = len(train_dataloader) * optimal_config.num_epochs // optimal_config.gradient_accumulation_steps\n",
    "\n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (warmup + linear decay)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=optimal_config.warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # í˜¼í•© ì •ë°€ë„ ìŠ¤ì¼€ì¼ëŸ¬\n",
    "        scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # í›ˆë ¨ ë£¨í”„\n",
    "        best_val_accuracy = 0\n",
    "        best_epoch = 0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(optimal_config.num_epochs):\n",
    "            print(f\"\\n--- Epoch {epoch + 1}/{optimal_config.num_epochs} ---\")\n",
    "            \n",
    "            # í›ˆë ¨\n",
    "            train_metrics = train_epoch(\n",
    "                model, train_dataloader, optimizer, scheduler, scaler, \n",
    "                fixed_config.device, optimal_config, criterion_fn\n",
    "            )\n",
    "            \n",
    "            # ê²€ì¦\n",
    "            val_metrics = validate_epoch(model, val_dataloader, fixed_config.device, criterion_fn)\n",
    "            \n",
    "            # WandB ë¡œê¹…\n",
    "            if optimal_config.use_wandb:\n",
    "                wandb.log({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_loss\": train_metrics['loss'],\n",
    "                    \"train_accuracy\": train_metrics['accuracy'],\n",
    "                    \"train_f1\": train_metrics['f1'],\n",
    "                    \"val_loss\": val_metrics['loss'],\n",
    "                    \"val_accuracy\": val_metrics['accuracy'],\n",
    "                    \"val_f1\": val_metrics['f1'],\n",
    "                    \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "            save_model(model, tokenizer, optimal_config.save_model_path + f\"_epoch_{epoch + 1}\", epoch + 1, val_metrics['accuracy'])\n",
    "            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "            if val_metrics['accuracy'] > best_val_accuracy:\n",
    "                best_val_accuracy = val_metrics['accuracy']\n",
    "                best_epoch = epoch + 1\n",
    "                patience_counter = 0\n",
    "                \n",
    "                #if optimal_config.save_best_model:\n",
    "                #   save_model(model, tokenizer, optimal_config.save_model_path, epoch + 1, val_metrics['accuracy'])\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1} ê²°ê³¼:\")\n",
    "            print(f\"  Train - Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}, F1: {train_metrics['f1']:.4f}\")\n",
    "            print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "            print(f\"  Best Val Accuracy: {best_val_accuracy:.4f} (Epoch {best_epoch})\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= optimal_config.early_stopping_patience:\n",
    "                print(f\"\\nâ¹ï¸  Early stopping at epoch {epoch + 1} (patience: {optimal_config.early_stopping_patience})\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!\")\n",
    "        print(f\"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_accuracy:.4f} (Epoch {best_epoch})\")\n",
    "        print(f\"ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {optimal_config.save_model_path}\")\n",
    "        \n",
    "        # ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹…\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"best_val_accuracy\": best_val_accuracy,\n",
    "                \"best_epoch\": best_epoch,\n",
    "                \"final_train_loss\": train_metrics['loss'],\n",
    "                \"final_train_accuracy\": train_metrics['accuracy'],\n",
    "                \"final_val_loss\": val_metrics['loss'],\n",
    "                \"final_val_accuracy\": val_metrics['accuracy']\n",
    "            })\n",
    "        \n",
    "        return best_val_accuracy, best_epoch\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.log({\"error\": str(e)})\n",
    "        raise e\n",
    "    finally:\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.finish()\n",
    "\n",
    "print(\"âœ… ìµœì¢… í›ˆë ¨ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìµœì¢… ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "í”„ë¡œì íŠ¸: [domain_project]_Final_Training_original\n",
      "ì‹¤í–‰ ì´ë¦„: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "ëª¨ë¸ ì €ì¥ ê²½ë¡œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqkdwodus777\u001b[0m (\u001b[33mqkdwodus777-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/code/wandb/run-20251030_090805-scd3xo5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42</a></strong> to <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì‹œì‘\n",
      "learning_rate: 1.00e-05\n",
      "batch_size: 400\n",
      "label_smoothing_factor: 0.120\n",
      "weight_decay: 0.040\n",
      "num_epochs: 4\n",
      "augment_ratio: 0.0\n",
      "ëª¨ë¸ ì €ì¥ ê²½ë¡œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "============================================================\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "âœ… ê²½ë¡œ í™•ì¸ë¨: /data/ephemeral/home/code/Final_Models/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ ëª¨ë¸ ë¡œë”© ì¤‘...\n",
      "âœ… ë¡œì»¬ ìŠ¤ëƒ…ìƒ·ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”© ì„±ê³µ!\n",
      "\n",
      "ë°ì´í„°ì…‹ ë¹„ìœ¨ì— ë”°ë¥¸ ìƒ˜í”Œë§ ì¤‘...\n",
      "ì›ë³¸ ë°ì´í„° ë¶„í¬:\n",
      "  Original: 136,453ê°œ\n",
      "  Augment: 407,336ê°œ\n",
      "\\nìƒ˜í”Œë§ëœ ë°ì´í„° ë¶„í¬:\n",
      "  Original: 136,453ê°œ (ë¹„ìœ¨: 1.0)\n",
      "  Augment: 0ê°œ (ë¹„ìœ¨: 0.0)\n",
      "  ì´ ë°ì´í„°: 136,453ê°œ\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a3cdc0fd154fb9ab8beef187be1238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817092266c34cf9bada9c3246cbcc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_1\n",
      "   Epoch: 1, Val Accuracy: 0.8498\n",
      "Epoch 1 ê²°ê³¼:\n",
      "  Train - Loss: 0.1244, Accuracy: 0.9283, F1: 0.9276\n",
      "  Val   - Loss: 0.2706, Accuracy: 0.8498, F1: 0.8488\n",
      "  Best Val Accuracy: 0.8498 (Epoch 1)\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054e5f56ee6406994e61d454eaff0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dba39aa7c304e3ca5e9127f7fa53ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_2\n",
      "   Epoch: 2, Val Accuracy: 0.8699\n",
      "Epoch 2 ê²°ê³¼:\n",
      "  Train - Loss: 0.1093, Accuracy: 0.9380, F1: 0.9375\n",
      "  Val   - Loss: 0.2425, Accuracy: 0.8699, F1: 0.8696\n",
      "  Best Val Accuracy: 0.8699 (Epoch 2)\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e69c8da1c341ee8c920c428fe11284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96a531c7b3f4d86ac6f8ff0e49340ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_3\n",
      "   Epoch: 3, Val Accuracy: 0.8806\n",
      "Epoch 3 ê²°ê³¼:\n",
      "  Train - Loss: 0.1005, Accuracy: 0.9435, F1: 0.9431\n",
      "  Val   - Loss: 0.2236, Accuracy: 0.8806, F1: 0.8794\n",
      "  Best Val Accuracy: 0.8806 (Epoch 3)\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beebaca186164d2480db37ae18dec298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f156a175f94a64adac54749c22976c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_4\n",
      "   Epoch: 4, Val Accuracy: 0.8858\n",
      "Epoch 4 ê²°ê³¼:\n",
      "  Train - Loss: 0.0951, Accuracy: 0.9466, F1: 0.9462\n",
      "  Val   - Loss: 0.2188, Accuracy: 0.8858, F1: 0.8847\n",
      "  Best Val Accuracy: 0.8858 (Epoch 4)\n",
      "\n",
      "ğŸ‰ í›ˆë ¨ ì™„ë£Œ!\n",
      "ìµœê³  ê²€ì¦ ì •í™•ë„: 0.8858 (Epoch 4)\n",
      "ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>â–</td></tr><tr><td>best_val_accuracy</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–ƒâ–†â–ˆ</td></tr><tr><td>final_train_accuracy</td><td>â–</td></tr><tr><td>final_train_loss</td><td>â–</td></tr><tr><td>final_val_accuracy</td><td>â–</td></tr><tr><td>final_val_loss</td><td>â–</td></tr><tr><td>learning_rate</td><td>â–ˆâ–†â–ƒâ–</td></tr><tr><td>train_accuracy</td><td>â–â–…â–‡â–ˆ</td></tr><tr><td>train_f1</td><td>â–â–…â–‡â–ˆ</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_accuracy</td><td>0.88583</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>final_train_accuracy</td><td>0.9466</td></tr><tr><td>final_train_loss</td><td>0.09513</td></tr><tr><td>final_val_accuracy</td><td>0.88583</td></tr><tr><td>final_val_loss</td><td>0.21881</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>train_accuracy</td><td>0.9466</td></tr><tr><td>train_f1</td><td>0.94618</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42</strong> at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w</a><br> View project at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251030_090805-scd3xo5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ ìµœì¢… í›ˆë ¨ ì™„ë£Œ!\n",
      "ìµœê³  ê²€ì¦ ì •í™•ë„: 0.8858\n",
      "ìµœê³  ì„±ëŠ¥ ì—í¬í¬: 4\n",
      "ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰\n",
    "print(\"ğŸš€ ìµœì¢… ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "print(f\"í”„ë¡œì íŠ¸: {optimal_config.project_name}\")\n",
    "print(f\"ì‹¤í–‰ ì´ë¦„: {RUN_NAME}\")\n",
    "print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {optimal_config.save_model_path}\")\n",
    "\n",
    "# í›ˆë ¨ ì‹¤í–‰\n",
    "best_accuracy, best_epoch = train_final_model()\n",
    "\n",
    "print(f\"\\nğŸ‰ ìµœì¢… í›ˆë ¨ ì™„ë£Œ!\")\n",
    "print(f\"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_accuracy:.4f}\")\n",
    "print(f\"ìµœê³  ì„±ëŠ¥ ì—í¬í¬: {best_epoch}\")\n",
    "print(f\"ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í‰ê°€ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def evaluate_model(model_path, test_data_path=None):\n",
    "    \"\"\"ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ í‰ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"\\nğŸ“Š ëª¨ë¸ í‰ê°€ ì‹œì‘: {model_path}\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, tokenizer = model_load_from_local(model_path, fixed_config.model_name)\n",
    "    if model is None or tokenizer is None:\n",
    "        print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "        return None\n",
    "    \n",
    "    model = model.to(fixed_config.device)\n",
    "    model.eval()\n",
    "    \n",
    "    # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    "    val_dataset = ReviewDataset(\n",
    "        val_df[\"review\"],\n",
    "        val_df[\"label\"],\n",
    "        tokenizer,\n",
    "        fixed_config.max_length,\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=optimal_config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # í‰ê°€ ì‹¤í–‰\n",
    "    val_metrics = validate_epoch(model, val_dataloader, fixed_config.device, \n",
    "                                lambda p, t: label_smoothing_cross_entropy(p, t, optimal_config.label_smoothing_factor))\n",
    "    \n",
    "    print(f\"âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ:\")\n",
    "    print(f\"  ê²€ì¦ ì •í™•ë„: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  ê²€ì¦ F1 ì ìˆ˜: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"  ê²€ì¦ ì†ì‹¤: {val_metrics['loss']:.4f}\")\n",
    "    \n",
    "    return val_metrics\n",
    "\n",
    "# ì €ì¥ëœ ëª¨ë¸ í‰ê°€\n",
    "if os.path.exists(optimal_config.save_model_path):\n",
    "    print(f\"\\nğŸ” ì €ì¥ëœ ëª¨ë¸ í‰ê°€ ì¤‘...\")\n",
    "    eval_metrics = evaluate_model(optimal_config.save_model_path)\n",
    "else:\n",
    "    print(f\"âŒ ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í›ˆë ¨ ê²°ê³¼ ìš”ì•½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ ìµœì¢… í›ˆë ¨ ê²°ê³¼ ìš”ì•½\n",
      "==================================================\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥:\n",
      "  ê²€ì¦ ì •í™•ë„: 0.8858\n",
      "  ìµœê³  ì„±ëŠ¥ ì—í¬í¬: 4\n",
      "\n",
      "âš™ï¸  ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°:\n",
      "  Learning Rate: 1.00e-05\n",
      "  Batch Size: 400\n",
      "  Label Smoothing Factor: 0.120\n",
      "  Weight Decay: 0.040\n",
      "  Epochs: 4\n",
      "\n",
      "ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì„±:\n",
      "  Augment Ratio: 0.0\n",
      "  Original Ratio: 1.0\n",
      "\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì •ë³´:\n",
      "  ì €ì¥ ê²½ë¡œ: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "  ëª¨ë¸ ì´ë¦„: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42\n",
      "  DAPT ì‚¬ìš©: True\n",
      "\n",
      "ğŸ”— WandB ì •ë³´:\n",
      "  í”„ë¡œì íŠ¸: [domain_project]_Final_Training_original\n",
      "  ì‹¤í–‰ ì´ë¦„: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "\n",
      "âœ… í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# í›ˆë ¨ ê²°ê³¼ ìš”ì•½\n",
    "print(\"ğŸ“‹ ìµœì¢… í›ˆë ¨ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ğŸ† ìµœê³  ì„±ëŠ¥:\")\n",
    "print(f\"  ê²€ì¦ ì •í™•ë„: {best_accuracy:.4f}\")\n",
    "print(f\"  ìµœê³  ì„±ëŠ¥ ì—í¬í¬: {best_epoch}\")\n",
    "\n",
    "print(f\"\\nâš™ï¸  ì‚¬ìš©ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"  Learning Rate: {optimal_config.learning_rate:.2e}\")\n",
    "print(f\"  Batch Size: {optimal_config.batch_size}\")\n",
    "print(f\"  Label Smoothing Factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "print(f\"  Weight Decay: {optimal_config.weight_decay:.3f}\")\n",
    "print(f\"  Epochs: {optimal_config.num_epochs}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ë°ì´í„°ì…‹ êµ¬ì„±:\")\n",
    "print(f\"  Augment Ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "print(f\"  Original Ratio: {optimal_config.original_ratio:.1f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì •ë³´:\")\n",
    "print(f\"  ì €ì¥ ê²½ë¡œ: {optimal_config.save_model_path}\")\n",
    "print(f\"  ëª¨ë¸ ì´ë¦„: {fixed_config.model_name}\")\n",
    "print(f\"  DAPT ì‚¬ìš©: {fixed_config.is_DAPT}\")\n",
    "\n",
    "print(f\"\\nğŸ”— WandB ì •ë³´:\")\n",
    "print(f\"  í”„ë¡œì íŠ¸: {optimal_config.project_name}\")\n",
    "print(f\"  ì‹¤í–‰ ì´ë¦„: {RUN_NAME}\")\n",
    "\n",
    "print(\"\\nâœ… í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”® ëª¨ë¸ ì˜ˆì¸¡ ì˜ˆì‹œ:\n",
      "========================================\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\n",
      "ë¡œì»¬ ê²½ë¡œì—ì„œ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\n",
      "\n",
      "âœ… ì˜ˆì¸¡ ì˜ˆì‹œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜\n",
    "def predict_sentiment(text, model_path=None):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if model_path is None:\n",
    "        model_path = optimal_config.save_model_path\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    model, tokenizer = model_load_from_local(model_path, fixed_config.model_name)\n",
    "    if model is None or tokenizer is None:\n",
    "        print(\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "        return None\n",
    "    \n",
    "    model = model.to(fixed_config.device)\n",
    "    model.eval()\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§•\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=fixed_config.max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"].to(fixed_config.device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(fixed_config.device)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # í´ë˜ìŠ¤ ë¼ë²¨ ë§¤í•‘\n",
    "    class_labels = {0: \"ë§¤ìš° ë¶€ì •\", 1: \"ë¶€ì •\", 2: \"ê¸ì •\", 3: \"ë§¤ìš° ê¸ì •\"}\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"predicted_label\": class_labels[predicted_class],\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": probabilities[0].cpu().numpy()\n",
    "    }\n",
    "\n",
    "# ì˜ˆì‹œ ì˜ˆì¸¡\n",
    "print(\"\\nğŸ”® ëª¨ë¸ ì˜ˆì¸¡ ì˜ˆì‹œ:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ë“¤\n",
    "example_texts = [\n",
    "    \"ì •ë§ ë§›ìˆì–´ìš”! ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤!\",\n",
    "    \"ë³„ë¡œë„¤ìš”. ê¸°ëŒ€í–ˆë˜ ê²ƒë³´ë‹¤ ì•„ì‰¬ì›Œìš”.\",\n",
    "    \"ê·¸ëƒ¥ ê·¸ëŸ° ê²ƒ ê°™ì•„ìš”.\",\n",
    "    \"ì™€! ì™„ì „ ìµœê³ ì˜ˆìš”! ë‹¤ì‹œ ì˜¬ ê±°ì˜ˆìš”!\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    result = predict_sentiment(text)\n",
    "    if result:\n",
    "        print(f\"\\ní…ìŠ¤íŠ¸: {result['text']}\")\n",
    "        print(f\"ì˜ˆì¸¡: {result['predicted_label']} (ì‹ ë¢°ë„: {result['confidence']:.3f})\")\n",
    "        print(f\"í™•ë¥  ë¶„í¬: {result['probabilities']}\")\n",
    "\n",
    "print(\"\\nâœ… ì˜ˆì¸¡ ì˜ˆì‹œ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
