{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 텍스트 감정 분석 - 최적화된 파인튜닝\n",
    "\n",
    "이 노트북은 WandB Sweep을 통해 찾은 최적의 하이퍼파라미터를 사용하여 최종 모델을 훈련합니다.\n",
    "\n",
    "## 주요 기능\n",
    "- 최적화된 하이퍼파라미터를 사용한 파인튜닝\n",
    "- DAPT (Domain-Adapted Pre-Training) 모델 사용\n",
    "- 데이터셋 비율 조정: original(1.0) : augment(3.0)\n",
    "- 모델 저장 및 평가\n",
    "- WandB를 통한 실험 추적\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# PEFT for LoRA\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 경고 메시지 필터링\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디바이스: cuda\n",
      "GPU 개수: 1\n",
      "   GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 이 함수가 .env 파일을 읽어서 환경 변수로 로드합니다.\n",
    "load_dotenv()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"디바이스: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"⚠️  CUDA 사용 불가 - CPU로 훈련 진행\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 고정 설정\n",
    "PROJECT_NAME = \"[domain_project]_Final_Training_original\"\n",
    "MODEL_NAME = \"TAPT_klue_Roberta-kor-base_final_training_2025-10-30_00-40-22_RANDOM_42\"\n",
    "RUN_NAME = f\"{MODEL_NAME}_final_training_{TIMESTAMP}_RANDOM_{RANDOM_STATE}\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 최적화된 하이퍼파라미터 설정 완료\n",
      "learning_rate: 1.00e-05\n",
      "batch_size: 400\n",
      "label_smoothing_factor: 0.120\n",
      "weight_decay: 0.040\n",
      "num_epochs: 4\n",
      "augment_ratio: 0.0\n",
      "모델 저장 경로: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# 최적화된 하이퍼파라미터 설정 (Sweep 결과 기반)\n",
    "class OptimalConfig:\n",
    "    # 최적화된 하이퍼파라미터 (Sweep에서 찾은 최고 성능)\n",
    "    learning_rate = 1e-05  \n",
    "    batch_size = 400\n",
    "    label_smoothing_factor = 0.12  \n",
    "    weight_decay = 0.04  \n",
    "    num_epochs = 4\n",
    "    augment_ratio = 0.0  # original 대비 3배\n",
    "\n",
    "    \n",
    "    # 데이터셋 비율 설정\n",
    "    original_ratio = 1.0  # 항상 1.0 (기준)\n",
    "    \n",
    "    # 기타 설정\n",
    "    warmup_steps = 10\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1.0\n",
    "    early_stopping_patience = 2\n",
    "    save_best_model = True  # 최고 성능 모델 저장\n",
    "    \n",
    "    # 모델 저장 경로\n",
    "    save_model_path = f\"./Final_Models/original/{RUN_NAME}\"\n",
    "    \n",
    "    # WandB 설정\n",
    "    use_wandb = True\n",
    "    project_name = PROJECT_NAME\n",
    "\n",
    "optimal_config = OptimalConfig()\n",
    "\n",
    "print(\"✅ 최적화된 하이퍼파라미터 설정 완료\")\n",
    "print(f\"learning_rate: {optimal_config.learning_rate:.2e}\")\n",
    "print(f\"batch_size: {optimal_config.batch_size}\")\n",
    "print(f\"label_smoothing_factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "print(f\"weight_decay: {optimal_config.weight_decay:.3f}\")\n",
    "print(f\"num_epochs: {optimal_config.num_epochs}\")\n",
    "print(f\"augment_ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "print(f\"모델 저장 경로: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 고정 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 고정 설정\n",
    "class FixedConfig:\n",
    "    # 모델 설정\n",
    "    model_name = MODEL_NAME\n",
    "    base_models_path = \"\"\n",
    "    local_model_path = base_models_path + MODEL_NAME\n",
    "\n",
    "    is_DAPT = True\n",
    "    DAPT_model_path = f\"/data/ephemeral/home/code/Final_Models/{MODEL_NAME}\"\n",
    "    \n",
    "    num_classes = 4\n",
    "    max_length = 128\n",
    "\n",
    "    # 데이터 설정\n",
    "    train_data_path = \"/data/ephemeral/home/code/data/train_final_augX3.csv\"\n",
    "    val_data_path = \"/data/ephemeral/home/code/data/val_final.csv\"\n",
    "    \n",
    "    # 고정 훈련 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Loss 설정\n",
    "    loss_function = \"CrossEntropy\"\n",
    "    use_label_smoothing = True\n",
    "    use_lora = False\n",
    "\n",
    "fixed_config = FixedConfig()\n",
    "print(\"✅ 고정 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 샘플링 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 비율에 따른 샘플링 함수\n",
    "def sample_dataset_by_ratio(df, augment_ratio=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    데이터셋을 비율에 따라 샘플링하는 함수\n",
    "    \n",
    "    Args:\n",
    "        df: 전체 데이터프레임\n",
    "        augment_ratio: augment 데이터 비율 (original 대비)\n",
    "        random_state: 랜덤 시드\n",
    "    \n",
    "    Returns:\n",
    "        sampled_df: 샘플링된 데이터프레임\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # 각 타입별 데이터 분리\n",
    "    original_data = df[df['type'] == 'original'].copy()\n",
    "    augment_data = df[df['type'] == 'augment'].copy()\n",
    "    \n",
    "    print(f\"원본 데이터 분포:\")\n",
    "    print(f\"  Original: {len(original_data):,}개\")\n",
    "    print(f\"  Augment: {len(augment_data):,}개\")\n",
    "    \n",
    "    # Original 데이터는 항상 100% 사용\n",
    "    sampled_original = original_data.copy()\n",
    "    \n",
    "    # Augment 데이터 샘플링\n",
    "    if augment_ratio > 0 and len(augment_data) > 0:\n",
    "        # original 대비 비율로 샘플링\n",
    "        target_augment_size = int(len(original_data) * augment_ratio)\n",
    "        if target_augment_size > len(augment_data):\n",
    "            # 요청된 크기가 전체보다 크면 전체 사용\n",
    "            sampled_augment = augment_data.copy()\n",
    "        else:\n",
    "            # 비율에 맞게 샘플링\n",
    "            sampled_augment = augment_data.sample(n=target_augment_size, random_state=random_state)\n",
    "    else:\n",
    "        sampled_augment = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    \n",
    "    # 샘플링된 데이터 합치기\n",
    "    sampled_df = pd.concat([sampled_original, sampled_augment], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\\\n샘플링된 데이터 분포:\")\n",
    "    print(f\"  Original: {len(sampled_original):,}개 (비율: 1.0)\")\n",
    "    print(f\"  Augment: {len(sampled_augment):,}개 (비율: {augment_ratio:.1f})\")\n",
    "    print(f\"  총 데이터: {len(sampled_df):,}개\")\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "print(\"✅ 데이터셋 샘플링 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 로드 중...\n",
      "전체 데이터: 536,966개\n",
      "검증 데이터: 6,823개\n",
      "전체 데이터: 543,789개\n",
      "✅ 데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 로드 (비율 샘플링을 위해)\n",
    "print(\"전체 데이터 로드 중...\")\n",
    "\n",
    "# 원본 데이터 로드 (preprocessing_final.ipynb에서 생성된 데이터)\n",
    "full_df = pd.read_csv(fixed_config.train_data_path)\n",
    "print(f\"전체 데이터: {len(full_df):,}개\")\n",
    "\n",
    "\n",
    "# 검증 데이터 로드 (original만 사용)\n",
    "val_df = pd.read_csv(fixed_config.val_data_path)\n",
    "\n",
    "full_df = pd.concat([full_df, val_df], ignore_index=True)\n",
    "print(f\"검증 데이터: {len(val_df):,}개\")\n",
    "print(f\"전체 데이터: {len(full_df):,}개\")\n",
    "print(\"✅ 데이터 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    리뷰 텍스트 데이셋 클래스\n",
    "    - BERT 모델 훈련/추론을 위한 PyTorch Dataset 구현\n",
    "    - 텍스트 토크나이징 및 텐서 변환 처리\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        데이터셋 초기화\n",
    "        \"\"\"\n",
    "        self.texts, self.labels, self.tokenizer, self.max_length = (\n",
    "            texts,\n",
    "            labels,\n",
    "            tokenizer,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋 크기 반환\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        특정 인덱스의 데이터 아이템 반환\n",
    "        \"\"\"\n",
    "        # 텍스트 토크나이징 및 패딩\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,  # 최대 길이 초과시 자르기\n",
    "            padding=\"max_length\",  # 최대 길이까지 패딩\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",  # PyTorch 텐서로 반환\n",
    "        )\n",
    "\n",
    "        # 기본 아이템 구성 (input_ids, attention_mask)\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        # labels가 None이 아닌 경우에만 추가 (train/valid용)\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "print(\"✅ 데이터셋 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 평가 메트릭 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 평가 메트릭 함수\n",
    "def compute_metrics(predictions, labels):\n",
    "    \"\"\"\n",
    "    모델 평가 메트릭 계산 함수\n",
    "    \"\"\"\n",
    "    # 예측값에서 가장 높은 확률의 클래스 선택\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "print(\"✅ 평가 메트릭 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_from_local(local_model_path : str = None, model_name : str = None):\n",
    "    # 1. 토크나이저 로드\n",
    "    # 절대 경로를 사용하여 로컬 모델 로드\n",
    "    print(\"로컬 경로에서 토크나이저 로딩 중...\")\n",
    "\n",
    "    # 경로가 존재하는지 확인\n",
    "    if not os.path.exists(local_model_path):\n",
    "        print(f\"❌ 경로가 존재하지 않습니다: {local_model_path}\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(f\"✅ 경로 확인됨: {local_model_path}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "    # 2. 모델 로드\n",
    "    # 마찬가지로 로컬 경로(local_model_path)를 사용\n",
    "    print(\"로컬 경로에서 모델 로딩 중...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        local_model_path,\n",
    "        num_labels=4,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    print(\"✅ 로컬 스냅샷에서 모델과 토크나이저 로딩 성공!\")\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label Smoothing 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def label_smoothing_cross_entropy(predictions, targets, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    predictions: 모델 출력 (logits) [batch_size, num_classes]\n",
    "    targets: 정답 라벨 (정수) [batch_size]\n",
    "    smoothing: smoothing factor\n",
    "    \"\"\"\n",
    "    num_classes = predictions.size(-1)\n",
    "    \n",
    "    # 하드 라벨을 원-핫으로 변환\n",
    "    true_dist = torch.zeros_like(predictions)\n",
    "    true_dist.fill_(smoothing / (num_classes - 1))\n",
    "    true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - smoothing)\n",
    "    \n",
    "    # KL divergence = Cross Entropy with smoothed labels\n",
    "    return F.kl_div(F.log_softmax(predictions, dim=1), true_dist, reduction='batchmean')\n",
    "\n",
    "print(\"✅ Label Smoothing 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, scaler, device, config, criterion_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # 배치를 디바이스로 이동\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # 혼합 정밀도 훈련\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "                logits = outputs.logits\n",
    "                loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
    "        \n",
    "        # 예측값 저장\n",
    "        predictions.extend(logits.detach().cpu().numpy())\n",
    "        labels.extend(batch_labels.detach().cpu().numpy())\n",
    "        \n",
    "        # 진행률 업데이트\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item() * config.gradient_accumulation_steps:.4f}',\n",
    "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 검증 함수\n",
    "def validate_epoch(model, dataloader, device, criterion_fn):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # 배치를 디바이스로 이동\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            loss = criterion_fn(logits, batch_labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 예측값 저장\n",
    "            predictions.extend(logits.detach().cpu().numpy())\n",
    "            labels.extend(batch_labels.detach().cpu().numpy())\n",
    "            \n",
    "            # 진행률 업데이트\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"✅ 검증 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 최종 훈련 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 함수\n",
    "def save_model(model, tokenizer, save_path, epoch, val_accuracy):\n",
    "    \"\"\"모델과 토크나이저를 저장하는 함수\"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # 모델 저장\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "    # 설정 정보 저장\n",
    "    config_info = {\n",
    "        \"epoch\": epoch,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"timestamp\": TIMESTAMP,\n",
    "        \"model_name\": fixed_config.model_name,\n",
    "        \"learning_rate\": optimal_config.learning_rate,\n",
    "        \"batch_size\": optimal_config.batch_size,\n",
    "        \"label_smoothing_factor\": optimal_config.label_smoothing_factor,\n",
    "        \"weight_decay\": optimal_config.weight_decay,\n",
    "        \"augment_ratio\": optimal_config.augment_ratio,\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(save_path, \"training_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✅ 모델 저장 완료: {save_path}\")\n",
    "    print(f\"   Epoch: {epoch}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# 메인 훈련 함수\n",
    "def train_final_model():\n",
    "    # WandB 초기화\n",
    "    if optimal_config.use_wandb:\n",
    "        run = wandb.init(\n",
    "            project=optimal_config.project_name,\n",
    "            name=RUN_NAME,\n",
    "            config={\n",
    "                \"learning_rate\": optimal_config.learning_rate,\n",
    "                \"batch_size\": optimal_config.batch_size,\n",
    "                \"label_smoothing_factor\": optimal_config.label_smoothing_factor,\n",
    "                \"weight_decay\": optimal_config.weight_decay,\n",
    "                \"num_epochs\": optimal_config.num_epochs,\n",
    "                \"augment_ratio\": optimal_config.augment_ratio,\n",
    "                \"model_name\": fixed_config.model_name,\n",
    "                \"is_DAPT\": fixed_config.is_DAPT\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"최종 모델 훈련 시작\")\n",
    "    print(f\"learning_rate: {optimal_config.learning_rate:.2e}\")\n",
    "    print(f\"batch_size: {optimal_config.batch_size}\")\n",
    "    print(f\"label_smoothing_factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "    print(f\"weight_decay: {optimal_config.weight_decay:.3f}\")\n",
    "    print(f\"num_epochs: {optimal_config.num_epochs}\")\n",
    "    print(f\"augment_ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "    print(f\"모델 저장 경로: {optimal_config.save_model_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # 모델 및 토크나이저 로드\n",
    "        if fixed_config.is_DAPT:\n",
    "            model, tokenizer = model_load_from_local(fixed_config.DAPT_model_path, fixed_config.model_name)\n",
    "        else:\n",
    "            model, tokenizer = model_load_from_local(fixed_config.local_model_path, fixed_config.model_name)\n",
    "        \n",
    "        if model is None or tokenizer is None:\n",
    "            print(\"❌ 모델 로드 실패\")\n",
    "            return\n",
    "        \n",
    "        model = model.to(fixed_config.device)\n",
    "        \n",
    "        # 비율에 따라 훈련 데이터 샘플링\n",
    "        print(\"\\n데이터셋 비율에 따른 샘플링 중...\")\n",
    "        train_df_sampled = sample_dataset_by_ratio(\n",
    "            full_df, \n",
    "            augment_ratio=optimal_config.augment_ratio, \n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        # 데이터셋 및 데이터로더 생성\n",
    "        train_dataset = ReviewDataset(\n",
    "            train_df_sampled[\"review\"],\n",
    "            train_df_sampled[\"label\"],\n",
    "            tokenizer,\n",
    "            fixed_config.max_length,\n",
    "        )\n",
    "\n",
    "        val_dataset = ReviewDataset(\n",
    "            val_df[\"review\"],\n",
    "            val_df[\"label\"],\n",
    "            tokenizer,\n",
    "            fixed_config.max_length,\n",
    "        )\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=optimal_config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=optimal_config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        \n",
    "        # 손실 함수 설정\n",
    "        def criterion_fn(predictions, targets):\n",
    "            return label_smoothing_cross_entropy(predictions, targets, optimal_config.label_smoothing_factor)\n",
    "        \n",
    "        # 옵티마이저 설정\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(),\n",
    "            lr=optimal_config.learning_rate,\n",
    "            weight_decay=optimal_config.weight_decay\n",
    "        )\n",
    "\n",
    "        # 전체 훈련 스텝 계산\n",
    "        total_steps = len(train_dataloader) * optimal_config.num_epochs // optimal_config.gradient_accumulation_steps\n",
    "\n",
    "        # 스케줄러 설정 (warmup + linear decay)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=optimal_config.warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # 혼합 정밀도 스케일러\n",
    "        scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # 훈련 루프\n",
    "        best_val_accuracy = 0\n",
    "        best_epoch = 0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(optimal_config.num_epochs):\n",
    "            print(f\"\\n--- Epoch {epoch + 1}/{optimal_config.num_epochs} ---\")\n",
    "            \n",
    "            # 훈련\n",
    "            train_metrics = train_epoch(\n",
    "                model, train_dataloader, optimizer, scheduler, scaler, \n",
    "                fixed_config.device, optimal_config, criterion_fn\n",
    "            )\n",
    "            \n",
    "            # 검증\n",
    "            val_metrics = validate_epoch(model, val_dataloader, fixed_config.device, criterion_fn)\n",
    "            \n",
    "            # WandB 로깅\n",
    "            if optimal_config.use_wandb:\n",
    "                wandb.log({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_loss\": train_metrics['loss'],\n",
    "                    \"train_accuracy\": train_metrics['accuracy'],\n",
    "                    \"train_f1\": train_metrics['f1'],\n",
    "                    \"val_loss\": val_metrics['loss'],\n",
    "                    \"val_accuracy\": val_metrics['accuracy'],\n",
    "                    \"val_f1\": val_metrics['f1'],\n",
    "                    \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "                })\n",
    "            save_model(model, tokenizer, optimal_config.save_model_path + f\"_epoch_{epoch + 1}\", epoch + 1, val_metrics['accuracy'])\n",
    "            # 최고 성능 모델 저장\n",
    "            if val_metrics['accuracy'] > best_val_accuracy:\n",
    "                best_val_accuracy = val_metrics['accuracy']\n",
    "                best_epoch = epoch + 1\n",
    "                patience_counter = 0\n",
    "                \n",
    "                #if optimal_config.save_best_model:\n",
    "                #   save_model(model, tokenizer, optimal_config.save_model_path, epoch + 1, val_metrics['accuracy'])\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1} 결과:\")\n",
    "            print(f\"  Train - Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}, F1: {train_metrics['f1']:.4f}\")\n",
    "            print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "            print(f\"  Best Val Accuracy: {best_val_accuracy:.4f} (Epoch {best_epoch})\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= optimal_config.early_stopping_patience:\n",
    "                print(f\"\\n⏹️  Early stopping at epoch {epoch + 1} (patience: {optimal_config.early_stopping_patience})\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\n🎉 훈련 완료!\")\n",
    "        print(f\"최고 검증 정확도: {best_val_accuracy:.4f} (Epoch {best_epoch})\")\n",
    "        print(f\"모델 저장 위치: {optimal_config.save_model_path}\")\n",
    "        \n",
    "        # 최종 메트릭 로깅\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"best_val_accuracy\": best_val_accuracy,\n",
    "                \"best_epoch\": best_epoch,\n",
    "                \"final_train_loss\": train_metrics['loss'],\n",
    "                \"final_train_accuracy\": train_metrics['accuracy'],\n",
    "                \"final_val_loss\": val_metrics['loss'],\n",
    "                \"final_val_accuracy\": val_metrics['accuracy']\n",
    "            })\n",
    "        \n",
    "        return best_val_accuracy, best_epoch\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 훈련 중 오류 발생: {str(e)}\")\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.log({\"error\": str(e)})\n",
    "        raise e\n",
    "    finally:\n",
    "        if optimal_config.use_wandb:\n",
    "            wandb.finish()\n",
    "\n",
    "print(\"✅ 최종 훈련 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 최종 모델 훈련을 시작합니다...\n",
      "프로젝트: [domain_project]_Final_Training_original\n",
      "실행 이름: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "모델 저장 경로: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqkdwodus777\u001b[0m (\u001b[33mqkdwodus777-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/code/wandb/run-20251030_090805-scd3xo5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42</a></strong> to <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "최종 모델 훈련 시작\n",
      "learning_rate: 1.00e-05\n",
      "batch_size: 400\n",
      "label_smoothing_factor: 0.120\n",
      "weight_decay: 0.040\n",
      "num_epochs: 4\n",
      "augment_ratio: 0.0\n",
      "모델 저장 경로: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "============================================================\n",
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "✅ 경로 확인됨: /data/ephemeral/home/code/Final_Models/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42\n",
      "로컬 경로에서 모델 로딩 중...\n",
      "✅ 로컬 스냅샷에서 모델과 토크나이저 로딩 성공!\n",
      "\n",
      "데이터셋 비율에 따른 샘플링 중...\n",
      "원본 데이터 분포:\n",
      "  Original: 136,453개\n",
      "  Augment: 407,336개\n",
      "\\n샘플링된 데이터 분포:\n",
      "  Original: 136,453개 (비율: 1.0)\n",
      "  Augment: 0개 (비율: 0.0)\n",
      "  총 데이터: 136,453개\n",
      "\n",
      "--- Epoch 1/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a3cdc0fd154fb9ab8beef187be1238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817092266c34cf9bada9c3246cbcc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_1\n",
      "   Epoch: 1, Val Accuracy: 0.8498\n",
      "Epoch 1 결과:\n",
      "  Train - Loss: 0.1244, Accuracy: 0.9283, F1: 0.9276\n",
      "  Val   - Loss: 0.2706, Accuracy: 0.8498, F1: 0.8488\n",
      "  Best Val Accuracy: 0.8498 (Epoch 1)\n",
      "\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054e5f56ee6406994e61d454eaff0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dba39aa7c304e3ca5e9127f7fa53ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_2\n",
      "   Epoch: 2, Val Accuracy: 0.8699\n",
      "Epoch 2 결과:\n",
      "  Train - Loss: 0.1093, Accuracy: 0.9380, F1: 0.9375\n",
      "  Val   - Loss: 0.2425, Accuracy: 0.8699, F1: 0.8696\n",
      "  Best Val Accuracy: 0.8699 (Epoch 2)\n",
      "\n",
      "--- Epoch 3/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e69c8da1c341ee8c920c428fe11284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96a531c7b3f4d86ac6f8ff0e49340ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_3\n",
      "   Epoch: 3, Val Accuracy: 0.8806\n",
      "Epoch 3 결과:\n",
      "  Train - Loss: 0.1005, Accuracy: 0.9435, F1: 0.9431\n",
      "  Val   - Loss: 0.2236, Accuracy: 0.8806, F1: 0.8794\n",
      "  Best Val Accuracy: 0.8806 (Epoch 3)\n",
      "\n",
      "--- Epoch 4/4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beebaca186164d2480db37ae18dec298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f156a175f94a64adac54749c22976c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_4\n",
      "   Epoch: 4, Val Accuracy: 0.8858\n",
      "Epoch 4 결과:\n",
      "  Train - Loss: 0.0951, Accuracy: 0.9466, F1: 0.9462\n",
      "  Val   - Loss: 0.2188, Accuracy: 0.8858, F1: 0.8847\n",
      "  Best Val Accuracy: 0.8858 (Epoch 4)\n",
      "\n",
      "🎉 훈련 완료!\n",
      "최고 검증 정확도: 0.8858 (Epoch 4)\n",
      "모델 저장 위치: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>▁</td></tr><tr><td>best_val_accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>█▆▃▁</td></tr><tr><td>train_accuracy</td><td>▁▅▇█</td></tr><tr><td>train_f1</td><td>▁▅▇█</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_accuracy</td><td>0.88583</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>final_train_accuracy</td><td>0.9466</td></tr><tr><td>final_train_loss</td><td>0.09513</td></tr><tr><td>final_val_accuracy</td><td>0.88583</td></tr><tr><td>final_val_loss</td><td>0.21881</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>train_accuracy</td><td>0.9466</td></tr><tr><td>train_f1</td><td>0.94618</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42</strong> at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original/runs/scd3xo5w</a><br> View project at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Final_Training_original</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251030_090805-scd3xo5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 최종 훈련 완료!\n",
      "최고 검증 정확도: 0.8858\n",
      "최고 성능 에포크: 4\n",
      "모델 저장 위치: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 훈련 실행\n",
    "print(\"🚀 최종 모델 훈련을 시작합니다...\")\n",
    "print(f\"프로젝트: {optimal_config.project_name}\")\n",
    "print(f\"실행 이름: {RUN_NAME}\")\n",
    "print(f\"모델 저장 경로: {optimal_config.save_model_path}\")\n",
    "\n",
    "# 훈련 실행\n",
    "best_accuracy, best_epoch = train_final_model()\n",
    "\n",
    "print(f\"\\n🎉 최종 훈련 완료!\")\n",
    "print(f\"최고 검증 정확도: {best_accuracy:.4f}\")\n",
    "print(f\"최고 성능 에포크: {best_epoch}\")\n",
    "print(f\"모델 저장 위치: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 저장된 모델을 찾을 수 없습니다: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 및 테스트 함수\n",
    "def evaluate_model(model_path, test_data_path=None):\n",
    "    \"\"\"저장된 모델을 로드하여 평가하는 함수\"\"\"\n",
    "    print(f\"\\n📊 모델 평가 시작: {model_path}\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model, tokenizer = model_load_from_local(model_path, fixed_config.model_name)\n",
    "    if model is None or tokenizer is None:\n",
    "        print(\"❌ 모델 로드 실패\")\n",
    "        return None\n",
    "    \n",
    "    model = model.to(fixed_config.device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 검증 데이터로 평가\n",
    "    val_dataset = ReviewDataset(\n",
    "        val_df[\"review\"],\n",
    "        val_df[\"label\"],\n",
    "        tokenizer,\n",
    "        fixed_config.max_length,\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=optimal_config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # 평가 실행\n",
    "    val_metrics = validate_epoch(model, val_dataloader, fixed_config.device, \n",
    "                                lambda p, t: label_smoothing_cross_entropy(p, t, optimal_config.label_smoothing_factor))\n",
    "    \n",
    "    print(f\"✅ 모델 평가 완료:\")\n",
    "    print(f\"  검증 정확도: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  검증 F1 점수: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"  검증 손실: {val_metrics['loss']:.4f}\")\n",
    "    \n",
    "    return val_metrics\n",
    "\n",
    "# 저장된 모델 평가\n",
    "if os.path.exists(optimal_config.save_model_path):\n",
    "    print(f\"\\n🔍 저장된 모델 평가 중...\")\n",
    "    eval_metrics = evaluate_model(optimal_config.save_model_path)\n",
    "else:\n",
    "    print(f\"❌ 저장된 모델을 찾을 수 없습니다: {optimal_config.save_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 결과 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 최종 훈련 결과 요약\n",
      "==================================================\n",
      "🏆 최고 성능:\n",
      "  검증 정확도: 0.8858\n",
      "  최고 성능 에포크: 4\n",
      "\n",
      "⚙️  사용된 하이퍼파라미터:\n",
      "  Learning Rate: 1.00e-05\n",
      "  Batch Size: 400\n",
      "  Label Smoothing Factor: 0.120\n",
      "  Weight Decay: 0.040\n",
      "  Epochs: 4\n",
      "\n",
      "📊 데이터셋 구성:\n",
      "  Augment Ratio: 0.0\n",
      "  Original Ratio: 1.0\n",
      "\n",
      "💾 모델 저장 정보:\n",
      "  저장 경로: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "  모델 이름: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42\n",
      "  DAPT 사용: True\n",
      "\n",
      "🔗 WandB 정보:\n",
      "  프로젝트: [domain_project]_Final_Training_original\n",
      "  실행 이름: TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "\n",
      "✅ 훈련이 성공적으로 완료되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 훈련 결과 요약\n",
    "print(\"📋 최종 훈련 결과 요약\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"🏆 최고 성능:\")\n",
    "print(f\"  검증 정확도: {best_accuracy:.4f}\")\n",
    "print(f\"  최고 성능 에포크: {best_epoch}\")\n",
    "\n",
    "print(f\"\\n⚙️  사용된 하이퍼파라미터:\")\n",
    "print(f\"  Learning Rate: {optimal_config.learning_rate:.2e}\")\n",
    "print(f\"  Batch Size: {optimal_config.batch_size}\")\n",
    "print(f\"  Label Smoothing Factor: {optimal_config.label_smoothing_factor:.3f}\")\n",
    "print(f\"  Weight Decay: {optimal_config.weight_decay:.3f}\")\n",
    "print(f\"  Epochs: {optimal_config.num_epochs}\")\n",
    "\n",
    "print(f\"\\n📊 데이터셋 구성:\")\n",
    "print(f\"  Augment Ratio: {optimal_config.augment_ratio:.1f}\")\n",
    "print(f\"  Original Ratio: {optimal_config.original_ratio:.1f}\")\n",
    "\n",
    "print(f\"\\n💾 모델 저장 정보:\")\n",
    "print(f\"  저장 경로: {optimal_config.save_model_path}\")\n",
    "print(f\"  모델 이름: {fixed_config.model_name}\")\n",
    "print(f\"  DAPT 사용: {fixed_config.is_DAPT}\")\n",
    "\n",
    "print(f\"\\n🔗 WandB 정보:\")\n",
    "print(f\"  프로젝트: {optimal_config.project_name}\")\n",
    "print(f\"  실행 이름: {RUN_NAME}\")\n",
    "\n",
    "print(\"\\n✅ 훈련이 성공적으로 완료되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔮 모델 예측 예시:\n",
      "========================================\n",
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "❌ 경로가 존재하지 않습니다: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "❌ 모델 로드 실패\n",
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "❌ 경로가 존재하지 않습니다: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "❌ 모델 로드 실패\n",
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "❌ 경로가 존재하지 않습니다: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "❌ 모델 로드 실패\n",
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "❌ 경로가 존재하지 않습니다: ./Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42\n",
      "❌ 모델 로드 실패\n",
      "\n",
      "✅ 예측 예시 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모델 사용 예시 함수\n",
    "def predict_sentiment(text, model_path=None):\n",
    "    \"\"\"텍스트의 감정을 예측하는 함수\"\"\"\n",
    "    if model_path is None:\n",
    "        model_path = optimal_config.save_model_path\n",
    "    \n",
    "    # 모델 로드\n",
    "    model, tokenizer = model_load_from_local(model_path, fixed_config.model_name)\n",
    "    if model is None or tokenizer is None:\n",
    "        print(\"❌ 모델 로드 실패\")\n",
    "        return None\n",
    "    \n",
    "    model = model.to(fixed_config.device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 텍스트 토크나이징\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=fixed_config.max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding[\"input_ids\"].to(fixed_config.device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(fixed_config.device)\n",
    "    \n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    # 클래스 라벨 매핑\n",
    "    class_labels = {0: \"매우 부정\", 1: \"부정\", 2: \"긍정\", 3: \"매우 긍정\"}\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"predicted_label\": class_labels[predicted_class],\n",
    "        \"confidence\": confidence,\n",
    "        \"probabilities\": probabilities[0].cpu().numpy()\n",
    "    }\n",
    "\n",
    "# 예시 예측\n",
    "print(\"\\n🔮 모델 예측 예시:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 예시 텍스트들\n",
    "example_texts = [\n",
    "    \"정말 맛있어요! 강력 추천합니다!\",\n",
    "    \"별로네요. 기대했던 것보다 아쉬워요.\",\n",
    "    \"그냥 그런 것 같아요.\",\n",
    "    \"와! 완전 최고예요! 다시 올 거예요!\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    result = predict_sentiment(text)\n",
    "    if result:\n",
    "        print(f\"\\n텍스트: {result['text']}\")\n",
    "        print(f\"예측: {result['predicted_label']} (신뢰도: {result['confidence']:.3f})\")\n",
    "        print(f\"확률 분포: {result['probabilities']}\")\n",
    "\n",
    "print(\"\\n✅ 예측 예시 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
