{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 텍스트 감정 분석 - PyTorch 모델 학습\n",
    "\n",
    "이 노트북은 전처리된 데이터를 사용하여 PyTorch 기반의 BERT/RoBERTa 모델을 학습합니다.\n",
    "\n",
    "## 주요 기능\n",
    "- PyTorch 네이티브 학습 루프 (Transformers Trainer 대신)\n",
    "- LoRA 파인튜닝\n",
    "- WandB 실험 추적\n",
    "- 혼합 정밀도 학습 (Mixed Precision)\n",
    "- 조기 종료 및 모델 체크포인팅\n",
    "- 테스트 데이터 추론 및 제출 파일 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "# PEFT for LoRA\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 경고 메시지 필터링\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디바이스: cuda\n",
      "GPU 개수: 1\n",
      "   GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 이 함수가 .env 파일을 읽어서 환경 변수로 로드합니다.\n",
    "load_dotenv()\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"디바이스: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"⚠️  CUDA 사용 불가 - CPU로 훈련 진행\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "molels = [\"beomi_kcbert-base\", \"klue_roberta-base\", \"klue_bert-base\",\"kykim_bert-base\", \"monologg_koelectra-base-v3-discriminator\"]\n",
    "\n",
    "# 라벨 매핑\n",
    "LABEL_MAPPING = {0: \"강한 부정\", 1: \"약한 부정\", 2: \"약한 긍정\", 3: \"강한 긍정\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = f\"newly_gen_added\"\n",
    "\n",
    "PROJECT_NAME = f\"[domain_project]_Experiments\"\n",
    "MODEL_NAME = \"kykim_bert-base\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 하이퍼파라미터 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "\n",
    "class Config:\n",
    "    # 모델 설정\n",
    "\n",
    "    model_name = MODEL_NAME\n",
    "    base_models_path = \"/data/ephemeral/home/code/basemodels/\"\n",
    "    local_model_path = base_models_path + MODEL_NAME\n",
    "\n",
    "    is_DAPT = True\n",
    "    #DAPT_model_path = \"./DAPT_models/\"+ \"kykim_bert-base_unsupervised_model_1025\"\n",
    "    DAPT_model_path = \"./kykim_bert-kor-base_augX2_TAPT_best_unsupervised_model_1026\"\n",
    "    \n",
    "    save_model_path = \"./DAPT_fine/\"+ RUN_NAME\n",
    "\n",
    "    num_classes = 4\n",
    "    max_length = 128\n",
    "\n",
    "    # 데이터 설정\n",
    "    train_data_path = \"/data/ephemeral/home/code/data/train_processed_newly_gen_added.csv\"\n",
    "    val_data_path = \"/data/ephemeral/home/code/data/val_processed_newly_gen_added.csv\"\n",
    "    \n",
    "    # 훈련 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    batch_size = 512\n",
    "    eval_batch_size = 512\n",
    "    num_epochs = 5\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 0.01\n",
    "    warmup_steps = 500\n",
    "    \n",
    "    # 기타 설정\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1.0\n",
    "    early_stopping_patience = 5\n",
    "    save_best_model = True\n",
    "    \n",
    "    # WandB 설정\n",
    "    use_wandb = True\n",
    "    project_name = PROJECT_NAME\n",
    "    run_name = f\"{RUN_NAME}-training\"\n",
    "\n",
    "    # Loss 설정\n",
    "    loss_function = \"CrossEntropy\"\n",
    "    use_label_smoothing = True\n",
    "    label_smoothing_factor = 0.1  # 추가 필요\n",
    "\n",
    "    use_lora = False\n",
    "    lora_r = 8                    # LoRA rank (차원)\n",
    "    lora_alpha = 16                # LoRA alpha (스케일링)\n",
    "    lora_dropout = 0.1             # LoRA dropout\n",
    "    lora_target_modules = [\"query\", \"key\", \"value\", \"dense\"]  # LoRA 적용할 모듈들\n",
    "    lora_bias = \"none\"             # bias 설정: \"none\", \"all\", \"lora_only\"\n",
    "    lora_task_type = \"SEQ_CLS\"     # 태스크 타입\n",
    "\n",
    "\n",
    "\n",
    "config = Config()\n",
    "print(\"✅ 하이퍼파라미터 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/code/wandb/run-20251028_015203-pki4c14k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments/runs/pki4c14k' target=\"_blank\">newly_gen_added-training</a></strong> to <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments/runs/pki4c14k' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments/runs/pki4c14k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WandB 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "# WandB 초기화\n",
    "if config.use_wandb:\n",
    "    run = wandb.init(\n",
    "        project=config.project_name,\n",
    "        name=config.run_name,\n",
    "        config={\n",
    "            \"model_name\": config.model_name,\n",
    "            \"num_epochs\": config.num_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"max_length\": config.max_length,\n",
    "            \"num_classes\": config.num_classes,\n",
    "            \"warmup_steps\": config.warmup_steps,\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "            \"lora_r\": config.lora_r,\n",
    "            \"lora_alpha\": config.lora_alpha,\n",
    "            \"lora_dropout\": config.lora_dropout,\n",
    "            \"random_seed\": RANDOM_STATE\n",
    "        }\n",
    "    )\n",
    "    print(\"✅ WandB 초기화 완료\")\n",
    "else:\n",
    "    print(\"⚠️  WandB 사용 안함\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 데이터 로드 중...\n",
      "훈련 데이터: 330,248개\n",
      "검증 데이터: 36,695개\n",
      "✅ 데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "print(\"전처리된 데이터 로드 중...\")\n",
    "\n",
    "# 훈련 데이터 로드\n",
    "train_df = pd.read_csv(config.train_data_path)\n",
    "print(f\"훈련 데이터: {len(train_df):,}개\")\n",
    "\n",
    "# 검증 데이터 로드\n",
    "val_df = pd.read_csv(config.val_data_path)\n",
    "print(f\"검증 데이터: {len(val_df):,}개\")\n",
    "\n",
    "\n",
    "print(\"✅ 데이터 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_artifect = wandb.Artifact(\n",
    "    name=\"preprocessed_dataset_augX2\",\n",
    "    type=\"dataset\",\n",
    "    description=\"split the augmented data 데이터 셋\"\n",
    ")\n",
    "\n",
    "dataset_artifect.add_file(\"data/train_processed.csv\")\n",
    "dataset_artifect.add_file(\"data/val_processed.csv\")\n",
    "\n",
    "run.log_artifact(dataset_artifect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 클래스 정의\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    리뷰 텍스트 데이셋 클래스\n",
    "    - BERT 모델 훈련/추론을 위한 PyTorch Dataset 구현\n",
    "    - 텍스트 토크나이징 및 텐서 변환 처리\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        데이터셋 초기화\n",
    "        \"\"\"\n",
    "        self.texts, self.labels, self.tokenizer, self.max_length = (\n",
    "            texts,\n",
    "            labels,\n",
    "            tokenizer,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋 크기 반환\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        특정 인덱스의 데이터 아이템 반환\n",
    "        \"\"\"\n",
    "        # 텍스트 토크나이징 및 패딩\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,  # 최대 길이 초과시 자르기\n",
    "            padding=\"max_length\",  # 최대 길이까지 패딩\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",  # PyTorch 텐서로 반환\n",
    "        )\n",
    "\n",
    "        # 기본 아이템 구성 (input_ids, attention_mask)\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        # labels가 None이 아닌 경우에만 추가 (train/valid용)\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "print(\"✅ 데이터셋 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 평가 메트릭 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 평가 메트릭 함수\n",
    "def compute_metrics(predictions, labels):\n",
    "    \"\"\"\n",
    "    모델 평가 메트릭 계산 함수\n",
    "    \"\"\"\n",
    "    # 예측값에서 가장 높은 확률의 클래스 선택\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "print(\"✅ 평가 메트릭 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load_from_local(local_model_path : str = None, model_name : str = None):\n",
    "    # 1. 토크나이저 로드\n",
    "    # 절대 경로를 사용하여 로컬 모델 로드\n",
    "    print(\"로컬 경로에서 토크나이저 로딩 중...\")\n",
    "\n",
    "    # 경로가 존재하는지 확인\n",
    "    if not os.path.exists(local_model_path):\n",
    "        print(f\"❌ 경로가 존재하지 않습니다: {local_model_path}\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(f\"✅ 경로 확인됨: {local_model_path}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "    # 2. 모델 로드\n",
    "    # 마찬가지로 로컬 경로(local_model_path)를 사용\n",
    "    print(\"로컬 경로에서 모델 로딩 중...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        local_model_path,\n",
    "        num_labels=4,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    print(\"✅ 로컬 스냅샷에서 모델과 토크나이저 로딩 성공!\")\n",
    "\n",
    "    # --- 이제 평소처럼 모델을 사용할 수 있습니다 ---\n",
    "    inputs = tokenizer(\"이 영화 정말 재미있네요!\", return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    print(outputs.logits)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./kykim_bert-kor-base_augX2_TAPT_best_unsupervised_model_1026 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 경로에서 토크나이저 로딩 중...\n",
      "✅ 경로 확인됨: ./kykim_bert-kor-base_augX2_TAPT_best_unsupervised_model_1026\n",
      "로컬 경로에서 모델 로딩 중...\n",
      "✅ 로컬 스냅샷에서 모델과 토크나이저 로딩 성공!\n",
      "tensor([[-0.0761,  0.2847, -0.2230,  0.0559]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if config.is_DAPT:\n",
    "    model, tokenizer = model_load_from_local(config.DAPT_model_path, config.model_name)\n",
    "else:\n",
    "    model, tokenizer = model_load_from_local(config.local_model_path, config.model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 및 토크나이저 로드 완료\n"
     ]
    }
   ],
   "source": [
    "#LoRA 설정 적용\n",
    "# print(\"LoRA 설정 적용 중...\")\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS,\n",
    "#     r=config.lora_r,\n",
    "#     lora_alpha=config.lora_alpha,\n",
    "#     target_modules=[\"query\", \"key\", \"value\"],\n",
    "#     lora_dropout=config.lora_dropout,\n",
    "#     bias=\"none\",\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, peft_config)\n",
    "# model.print_trainable_parameters()\n",
    "\n",
    "# 모델을 디바이스로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"✅ 모델 및 토크나이저 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Focal Loss 구현 (개선된 버전)\n",
    "#     - 클래스 불균형 문제 해결을 위한 손실 함수\n",
    "#     - 쉬운 샘플의 기여도를 줄이고 어려운 샘플에 집중\n",
    "#     \"\"\"\n",
    "#     def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             alpha (list, tensor, float, int, optional): \n",
    "#                 - list/tensor: 클래스별 가중치. [num_classes] 형태.\n",
    "#                 - float/int: 모든 클래스에 동일하게 적용될 단일 가중치.\n",
    "#             gamma (float): focusing parameter (기본값: 2.0)\n",
    "#             reduction (str): 'mean', 'sum', 'none'\n",
    "#         \"\"\"\n",
    "#         super(FocalLoss, self).__init__()\n",
    "        \n",
    "#         # --- [수정된 부분 1] ---\n",
    "#         # alpha를 tensor로 변환하고 버퍼로 등록\n",
    "#         if alpha is not None:\n",
    "#             if isinstance(alpha, (float, int)):\n",
    "#                 # 단일 값인 경우, 텐서로 만들 필요 없이 그대로 사용\n",
    "#                 self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "#             elif isinstance(alpha, (list, torch.Tensor)):\n",
    "#                 if isinstance(alpha, list):\n",
    "#                     alpha_tensor = torch.tensor(alpha, dtype=torch.float32)\n",
    "#                 else:\n",
    "#                     alpha_tensor = alpha.clone().detach().to(dtype=torch.float32)\n",
    "#                 # register_buffer: 모델의 state_dict에 포함되지만, \n",
    "#                 # optimzer에 의해 업데이트(학습)되지는 않음.\n",
    "#                 # .to(device) 호출 시 함께 이동함.\n",
    "#                 self.register_buffer('alpha', alpha_tensor)\n",
    "#             else:\n",
    "#                 raise TypeError(\"alpha must be a float, int, list, or torch.Tensor\")\n",
    "#         else:\n",
    "#             self.alpha = None\n",
    "#         # --- [수정 끝] ---\n",
    "            \n",
    "#         self.gamma = gamma\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             inputs: 모델 출력 (logits) [batch_size, num_classes]\n",
    "#             targets: 정답 라벨 [batch_size]\n",
    "#         \"\"\"\n",
    "#         # Cross Entropy Loss 계산 (reduction='none'이 중요)\n",
    "#         # ce_loss = -log(pt)\n",
    "#         ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        \n",
    "#         # 확률 계산 (pt = exp(-ce_loss))\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "        \n",
    "#         # Focal Loss 계산\n",
    "#         focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "#         # Alpha 가중치 적용\n",
    "#         if self.alpha is not None:\n",
    "#             # --- [수정된 부분 2] ---\n",
    "#             # self.alpha가 스칼라 텐서인지(float/int에서 변환됨) \n",
    "#             # 아니면 벡터 텐서(list에서 변환됨)인지 확인\n",
    "            \n",
    "#             # .to(device)를 명시적으로 호출하여 디바이스 일치 보장\n",
    "#             alpha = self.alpha.to(targets.device) \n",
    "\n",
    "#             if alpha.numel() == 1:\n",
    "#                 # alpha가 단일 값(float/int)에서 온 경우\n",
    "#                 alpha_t = alpha\n",
    "#             else:\n",
    "#                 # alpha가 list/tensor에서 온 경우 (클래스별 가중치)\n",
    "#                 # targets를 인덱스로 사용\n",
    "#                 alpha_t = alpha[targets]\n",
    "#             # --- [수정 끝] ---\n",
    "                \n",
    "#             focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "#         # Reduction 적용\n",
    "#         if self.reduction == 'mean':\n",
    "#             return focal_loss.mean()\n",
    "#         elif self.reduction == 'sum':\n",
    "#             return focal_loss.sum()\n",
    "#         else:\n",
    "#             return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 분포:\n",
      "  클래스 0: 121,917개 (36.9%)\n",
      "  클래스 1: 44,751개 (13.6%)\n",
      "  클래스 2: 108,355개 (32.8%)\n",
      "  클래스 3: 55,225개 (16.7%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_weights(labels):\n",
    "    \"\"\"클래스별 가중치 계산\"\"\"\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    classes = np.unique(labels)\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=classes,\n",
    "        y=labels\n",
    "    )\n",
    "    return torch.FloatTensor(class_weights)\n",
    "\n",
    "train_labels = train_df[\"label\"].values\n",
    "class_counts = np.bincount(train_labels)\n",
    "print(\"클래스별 분포:\")\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"  클래스 {i}: {count:,}개 ({count/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "# Focal Loss용 Alpha 계산\n",
    "# if config.use_focal_loss:\n",
    "#     if config.focal_alpha is None:\n",
    "#         # 자동으로 클래스 가중치 계산\n",
    "#         focal_alpha = calculate_class_weights(train_labels)\n",
    "#         print(f\"계산된 Alpha 가중치: {focal_alpha}\")\n",
    "#     else:\n",
    "#         focal_alpha = torch.FloatTensor(config.focal_alpha)\n",
    "#         print(f\"설정된 Alpha 가중치: {focal_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def label_smoothing_cross_entropy(predictions, targets, smoothing=0.1):\n",
    "    \"\"\"\n",
    "    predictions: 모델 출력 (logits) [batch_size, num_classes]\n",
    "    targets: 정답 라벨 (정수) [batch_size]\n",
    "    smoothing: smoothing factor\n",
    "    \"\"\"\n",
    "    num_classes = predictions.size(-1)\n",
    "    \n",
    "    # 하드 라벨을 원-핫으로 변환\n",
    "    true_dist = torch.zeros_like(predictions)\n",
    "    true_dist.fill_(smoothing / (num_classes - 1))\n",
    "    true_dist.scatter_(1, targets.unsqueeze(1), 1.0 - smoothing)\n",
    "    \n",
    "    # KL divergence = Cross Entropy with smoothed labels\n",
    "    return F.kl_div(F.log_softmax(predictions, dim=1), true_dist, reduction='batchmean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOSS 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cross Entropy Loss 사용\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 설정\n",
    "if config.loss_function == \"FocalLoss\":\n",
    "    criterion = FocalLoss(\n",
    "        alpha=focal_alpha,\n",
    "        gamma=config.focal_gamma,\n",
    "        reduction=config.focal_reduction\n",
    "    )\n",
    "    print(\"✅ Focal Loss 사용\")\n",
    "elif config.loss_function == \"WeightedCrossEntropy\":\n",
    "    weights = calculate_class_weights(train_labels)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "    print(\"✅ Weighted Cross Entropy Loss 사용\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(\"✅ Cross Entropy Loss 사용\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Label Smoothing Cross Entropy 사용\n"
     ]
    }
   ],
   "source": [
    "if config.use_label_smoothing:\n",
    "    def criterion_fn(predictions, targets):\n",
    "        return label_smoothing_cross_entropy(predictions, targets, config.label_smoothing_factor)\n",
    "    print(\"✅ Label Smoothing Cross Entropy 사용\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(\"✅ 일반 Cross Entropy Loss 사용\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 및 데이터로더 생성 중...\n",
      "훈련 데이터: 330,248개\n",
      "검증 데이터: 36,695개\n",
      "✅ 데이터셋 및 데이터로더 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "print(\"데이터셋 및 데이터로더 생성 중...\")\n",
    "\n",
    "# 훈련 데이터셋 생성\n",
    "train_dataset = ReviewDataset(\n",
    "    train_df[\"review\"],\n",
    "    train_df[\"label\"],\n",
    "    tokenizer,\n",
    "    config.max_length,\n",
    ")\n",
    "\n",
    "# 검증 데이터셋 생성\n",
    "val_dataset = ReviewDataset(\n",
    "    val_df[\"review\"],\n",
    "    val_df[\"label\"],\n",
    "    tokenizer,\n",
    "    config.max_length,\n",
    ")\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"훈련 데이터: {len(train_dataset):,}개\")\n",
    "print(f\"검증 데이터: {len(val_dataset):,}개\")\n",
    "print(\"✅ 데이터셋 및 데이터로더 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "옵티마이저 및 스케줄러 설정 중...\n",
      "총 훈련 스텝: 3,230\n",
      "워밍업 스텝: 500\n",
      "✅ 옵티마이저 및 스케줄러 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 스케줄러 설정\n",
    "print(\"옵티마이저 및 스케줄러 설정 중...\")\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# 전체 훈련 스텝 계산\n",
    "total_steps = len(train_dataloader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "\n",
    "# 스케줄러 설정 (warmup + linear decay)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=config.warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# 혼합 정밀도 스케일러\n",
    "scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "print(f\"총 훈련 스텝: {total_steps:,}\")\n",
    "print(f\"워밍업 스텝: {config.warmup_steps:,}\")\n",
    "print(\"✅ 옵티마이저 및 스케줄러 설정 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, scaler, device, config, criterion):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # 배치를 디바이스로 이동\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        batch_labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # 혼합 정밀도 훈련\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                    # labels=batch_labels  # 제거\n",
    "                )\n",
    "\n",
    "                logits = outputs.logits\n",
    "   \n",
    "                if config.use_label_smoothing:\n",
    "                    loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "                else:\n",
    "                    loss = criterion(logits, batch_labels)  / config.gradient_accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                # labels=batch_labels  # 제거\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "            if config.use_label_smoothing:\n",
    "                loss = criterion_fn(logits, batch_labels) / config.gradient_accumulation_steps\n",
    "            else:\n",
    "                loss = criterion(logits, batch_labels)  / config.gradient_accumulation_steps\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * config.gradient_accumulation_steps\n",
    "        \n",
    "        # 예측값 저장\n",
    "        predictions.extend(logits.detach().cpu().numpy())\n",
    "        labels.extend(batch_labels.detach().cpu().numpy())\n",
    "        \n",
    "        # 진행률 업데이트\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item() * config.gradient_accumulation_steps:.4f}',\n",
    "            'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 검증 함수\n",
    "def validate_epoch(model, dataloader, device, criterion):\n",
    "    \"\"\"한 에포크 검증 (Focal Loss 지원)\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            # 배치를 디바이스로 이동\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            batch_labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # 순전파\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                # labels=batch_labels  # 제거\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "\n",
    "            if config.use_label_smoothing:\n",
    "                loss = criterion_fn(logits, batch_labels)\n",
    "            else:\n",
    "                loss = criterion(logits, batch_labels)\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 예측값 저장\n",
    "            predictions.extend(logits.detach().cpu().numpy())\n",
    "            labels.extend(batch_labels.detach().cpu().numpy())\n",
    "            \n",
    "            # 진행률 업데이트\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    metrics = compute_metrics(predictions, labels)\n",
    "    metrics['loss'] = total_loss / len(dataloader)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"✅ 검증 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "모델 훈련 시작\n",
      "==================================================\n",
      "훈련 샘플: 330,248개\n",
      "검증 샘플: 36,695개\n",
      "훈련 에포크: 5회\n",
      "배치 크기: 512 (훈련) / 512 (검증)\n",
      "학습률: 2e-05\n",
      "시드값: 42\n",
      "디바이스: cuda\n",
      "WandB 사용: True\n",
      "\n",
      "==================== Epoch 1/5 ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ecf358dd9745f9b018b936adc01ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3f81f49a984722a2b1fa43ecfb1c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 결과:\n",
      "  Loss: 0.3507\n",
      "  Accuracy: 0.7816\n",
      "  F1: 0.7793\n",
      "\n",
      "검증 결과:\n",
      "  Loss: 0.2294\n",
      "  Accuracy: 0.8659\n",
      "  F1: 0.8651\n",
      "✅ 최고 성능 모델 저장 (Accuracy: 0.8659)\n",
      "\n",
      "==================== Epoch 2/5 ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8738bed0e4cd47ffb7a73c834a6d2814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2aed3d91e6a442599e7bfc93c277f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 결과:\n",
      "  Loss: 0.2114\n",
      "  Accuracy: 0.8752\n",
      "  F1: 0.8742\n",
      "\n",
      "검증 결과:\n",
      "  Loss: 0.2156\n",
      "  Accuracy: 0.8749\n",
      "  F1: 0.8738\n",
      "✅ 최고 성능 모델 저장 (Accuracy: 0.8749)\n",
      "\n",
      "==================== Epoch 3/5 ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a944938b4c4da3a9c80c800a89d62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc49fc83696844a28afb2fde11930b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 결과:\n",
      "  Loss: 0.1802\n",
      "  Accuracy: 0.8956\n",
      "  F1: 0.8950\n",
      "\n",
      "검증 결과:\n",
      "  Loss: 0.2122\n",
      "  Accuracy: 0.8783\n",
      "  F1: 0.8782\n",
      "✅ 최고 성능 모델 저장 (Accuracy: 0.8783)\n",
      "\n",
      "==================== Epoch 4/5 ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda5a34714bd4b0ca631330591914507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c68341caada47c6862fa88cefa22d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 결과:\n",
      "  Loss: 0.1573\n",
      "  Accuracy: 0.9109\n",
      "  F1: 0.9104\n",
      "\n",
      "검증 결과:\n",
      "  Loss: 0.2138\n",
      "  Accuracy: 0.8795\n",
      "  F1: 0.8796\n",
      "✅ 최고 성능 모델 저장 (Accuracy: 0.8795)\n",
      "\n",
      "==================== Epoch 5/5 ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158c86262c57492bba54d617ac7ccc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/646 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358d9662d8a44095a30b4f4ed51a46a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 결과:\n",
      "  Loss: 0.1415\n",
      "  Accuracy: 0.9212\n",
      "  F1: 0.9209\n",
      "\n",
      "검증 결과:\n",
      "  Loss: 0.2166\n",
      "  Accuracy: 0.8806\n",
      "  F1: 0.8804\n",
      "✅ 최고 성능 모델 저장 (Accuracy: 0.8806)\n",
      "\n",
      "✅ 훈련 완료!\n",
      "최고 검증 정확도: 0.8806\n"
     ]
    }
   ],
   "source": [
    "# 메인 훈련 루프\n",
    "print(\"=\" * 50)\n",
    "print(\"모델 훈련 시작\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 훈련 정보 출력\n",
    "print(f\"훈련 샘플: {len(train_dataset):,}개\")\n",
    "print(f\"검증 샘플: {len(val_dataset):,}개\")\n",
    "print(f\"훈련 에포크: {config.num_epochs}회\")\n",
    "print(f\"배치 크기: {config.batch_size} (훈련) / {config.eval_batch_size} (검증)\")\n",
    "print(f\"학습률: {config.learning_rate}\")\n",
    "print(f\"시드값: {RANDOM_STATE}\")\n",
    "print(f\"디바이스: {device}\")\n",
    "print(f\"WandB 사용: {config.use_wandb}\")\n",
    "\n",
    "# 조기 종료 및 체크포인팅 설정\n",
    "best_val_accuracy = 0\n",
    "patience_counter = 0\n",
    "training_history = []\n",
    "\n",
    "# 훈련 시작\n",
    "try:\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"\\n{'='*20} Epoch {epoch+1}/{config.num_epochs} {'='*20}\")\n",
    "        \n",
    "        # 훈련\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_dataloader, optimizer, scheduler, scaler, device, config, criterion\n",
    "        )\n",
    "        \n",
    "        # 검증\n",
    "        val_metrics = validate_epoch(model, val_dataloader, device, criterion)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"\\n훈련 결과:\")\n",
    "        print(f\"  Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  F1: {train_metrics['f1']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n검증 결과:\")\n",
    "        print(f\"  Loss: {val_metrics['loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  F1: {val_metrics['f1']:.4f}\")\n",
    "        \n",
    "        # WandB 로깅\n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": train_metrics['loss'],\n",
    "                \"train_accuracy\": train_metrics['accuracy'],\n",
    "                \"train_f1\": train_metrics['f1'],\n",
    "                \"val_loss\": val_metrics['loss'],\n",
    "                \"val_accuracy\": val_metrics['accuracy'],\n",
    "                \"val_f1\": val_metrics['f1'],\n",
    "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "            })\n",
    "        \n",
    "        # 히스토리 저장\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'train_accuracy': train_metrics['accuracy'],\n",
    "            'train_f1': train_metrics['f1'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_accuracy': val_metrics['accuracy'],\n",
    "            'val_f1': val_metrics['f1']\n",
    "        })\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if config.save_best_model and val_metrics['accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = val_metrics['accuracy']\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # 모델 저장\n",
    "            os.makedirs(config.save_model_path, exist_ok=True)\n",
    "            model.save_pretrained(f\"{config.save_model_path}_{TIMESTAMP}\")\n",
    "            tokenizer.save_pretrained(f\"{config.save_model_path}_{TIMESTAMP}\")\n",
    "\n",
    "            print(f\"✅ 최고 성능 모델 저장 (Accuracy: {best_val_accuracy:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # 조기 종료 체크\n",
    "        if patience_counter >= config.early_stopping_patience:\n",
    "            print(f\"\\n⚠️  조기 종료: {config.early_stopping_patience} 에포크 동안 개선 없음\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n✅ 훈련 완료!\")\n",
    "    print(f\"최고 검증 정확도: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⚠️  사용자에 의해 훈련이 중단되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ 훈련 중 오류 발생: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (DAPT_fine/newly_gen_added_2025-10-28_01-51-51)... Done. 3.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact model>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_artifect = wandb.Artifact(\n",
    "    name=\"model\",\n",
    "    type=\"model\",\n",
    "    description=\"config.model_name\"\n",
    ")\n",
    "model_artifect.add_dir(f\"{config.save_model_path}_{TIMESTAMP}\")\n",
    "run.log_artifact(model_artifect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 추론 시작...\n",
      "테스트 데이터: 59,928개\n",
      "최고 성능 모델 로드 중...\n",
      "✅ 최고 성능 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 추론\n",
    "print(\"테스트 데이터 추론 시작...\")\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv(\"data/test_processed.csv\")\n",
    "print(f\"테스트 데이터: {len(test_df):,}개\")\n",
    "\n",
    "# 최고 성능 모델 로드\n",
    "#if os.path.exists(config.save_model_path):\n",
    "if os.path.exists(config.save_model_path):\n",
    "    print(\"최고 성능 모델 로드 중...\")\n",
    "    inference_model = AutoModelForSequenceClassification.from_pretrained(f\"{config.save_model_path}_{TIMESTAMP}\")\n",
    "    inference_tokenizer = AutoTokenizer.from_pretrained(f\"{config.save_model_path}_{TIMESTAMP}\")\n",
    "    inference_model = inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "    print(\"✅ 최고 성능 모델 로드 완료\")\n",
    "else:\n",
    "    print(\"⚠️  저장된 모델이 없습니다. 현재 모델 사용\")\n",
    "    inference_model = model\n",
    "    inference_tokenizer = tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터셋 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋 및 데이터로더 생성\n",
    "test_dataset = ReviewDataset(\n",
    "    test_df[\"review\"],\n",
    "    None,  # 테스트 데이터는 라벨 없음\n",
    "    inference_tokenizer,\n",
    "    config.max_length,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.eval_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"✅ 테스트 데이터셋 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추론 실행 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d4919f688a466a8bae1267bf013592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 추론 완료: 59,928개 예측\n"
     ]
    }
   ],
   "source": [
    "# 추론 실행\n",
    "print(\"추론 실행 중...\")\n",
    "inference_model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Inference\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        outputs = inference_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        batch_predictions = torch.argmax(logits, dim=-1)\n",
    "        predictions.extend(batch_predictions.cpu().numpy())\n",
    "\n",
    "print(f\"✅ 추론 완료: {len(predictions):,}개 예측\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제출 파일 생성 중...\n",
      "\n",
      "클래스별 예측 분포:\n",
      "   강한 부정 (0): 24,895개 (41.5%)\n",
      "   약한 부정 (1): 5,377개 (9.0%)\n",
      "   약한 긍정 (2): 20,879개 (34.8%)\n",
      "   강한 긍정 (3): 8,777개 (14.6%)\n",
      "✅ 제출 파일 검증 통과\n",
      "✅ 제출 파일 저장 완료: ./DAPT_fine/newly_gen_added_output_2025-10-28_01-51-51.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇█</td></tr><tr><td>train_f1</td><td>▁▆▇▇█</td></tr><tr><td>train_loss</td><td>█▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇██</td></tr><tr><td>val_f1</td><td>▁▅▇██</td></tr><tr><td>val_loss</td><td>█▂▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>train_accuracy</td><td>0.92124</td></tr><tr><td>train_f1</td><td>0.92089</td></tr><tr><td>train_loss</td><td>0.1415</td></tr><tr><td>val_accuracy</td><td>0.88058</td></tr><tr><td>val_f1</td><td>0.88037</td></tr><tr><td>val_loss</td><td>0.21662</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">newly_gen_added-training</strong> at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments/runs/pki4c14k' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments/runs/pki4c14k</a><br> View project at: <a href='https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments' target=\"_blank\">https://wandb.ai/qkdwodus777-/%5Bdomain_project%5D_Experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251028_015203-pki4c14k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WandB 세션 종료\n",
      "\n",
      "🎉 모든 작업 완료!\n"
     ]
    }
   ],
   "source": [
    "# 제출 파일 생성\n",
    "print(\"제출 파일 생성 중...\")\n",
    "\n",
    "# 예측 결과를 데이터프레임에 추가\n",
    "test_df[\"pred\"] = predictions\n",
    "\n",
    "# 클래스별 예측 분포 확인\n",
    "unique_predictions, counts = np.unique(predictions, return_counts=True)\n",
    "print(\"\\n클래스별 예측 분포:\")\n",
    "for pred, count in zip(unique_predictions, counts):\n",
    "    percentage = (count / len(predictions)) * 100\n",
    "    class_name = LABEL_MAPPING.get(pred, f\"클래스 {pred}\")\n",
    "    print(f\"   {class_name} ({pred}): {count:,}개 ({percentage:.1f}%)\")\n",
    "\n",
    "# 샘플 제출 파일 로드\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "# ID를 기준으로 병합하여 제출 파일 생성\n",
    "submission_df = sample_submission[[\"ID\"]].merge(\n",
    "    test_df[[\"ID\", \"pred\"]], \n",
    "    left_on=\"ID\", \n",
    "    right_on=\"ID\", \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 제출 파일 검증\n",
    "assert len(submission_df) == len(sample_submission), f\"길이 불일치: {len(submission_df)} vs {len(sample_submission)}\"\n",
    "assert submission_df[\"pred\"].isin([0, 1, 2, 3]).all(), \"모든 예측값은 [0, 1, 2, 3] 범위에 있어야 합니다\"\n",
    "assert not submission_df[\"pred\"].isnull().any(), \"예측값에 null 값이 있으면 안됩니다\"\n",
    "assert not submission_df[\"ID\"].isnull().any(), \"ID 컬럼에 null 값이 있으면 안됩니다\"\n",
    "\n",
    "print(\"✅ 제출 파일 검증 통과\")\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission_path = f\"{config.save_model_path}_output_{TIMESTAMP}.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✅ 제출 파일 저장 완료: {submission_path}\")\n",
    "\n",
    "# WandB 종료\n",
    "if config.use_wandb:\n",
    "    wandb.finish()\n",
    "    print(\"✅ WandB 세션 종료\")\n",
    "\n",
    "print(\"\\n🎉 모든 작업 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
