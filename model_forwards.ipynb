{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99697bac",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ train dataì™€ test dataì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ\n",
    "- Train dataì™€ Test dataì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "- ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "- ì˜ˆì¸¡ ì„±ëŠ¥ ë¶„ì„ ë° ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636f74ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f7c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ë°”ì´ìŠ¤: cuda\n",
      "GPU ê°œìˆ˜: 1\n",
      "   GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ì„¤ì •\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU ê°œìˆ˜: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ ì¶”ë¡  ì§„í–‰\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b2c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ\n",
      "ëª¨ë¸ ê²½ë¡œ: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2\n",
      "ì¶œë ¥ ë””ë ‰í† ë¦¬: ./predictions\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì •\n",
    "MODEL_FOLDER = \"./Final_Models/original\"\n",
    "MODEL_NAME = \"/data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_3\"\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER, MODEL_NAME)  # í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ\n",
    "\n",
    "TRAIN_DATA_PATH = \"/data/ephemeral/home/code/data/train_final_augX3.csv\"\n",
    "TEST_DATA_PATH = \"/data/ephemeral/home/code/data/test_processed.csv\"\n",
    "VAL_DATA_PATH = \"/data/ephemeral/home/code/data/val_final.csv\"\n",
    "\n",
    "# ì¶œë ¥ ê²½ë¡œ\n",
    "OUTPUT_DIR = \"./predictions\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¼ë²¨ ë§¤í•‘\n",
    "LABEL_MAPPING = {0: \"ë§¤ìš° ë¶€ì •\", 1: \"ë¶€ì •\", 2: \"ê¸ì •\", 3: \"ë§¤ìš° ê¸ì •\"}\n",
    "REVERSE_LABEL_MAPPING = {v: k for k, v in LABEL_MAPPING.items()}\n",
    "\n",
    "print(\"âœ… ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}\")\n",
    "print(f\"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe11d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = f\"[domain_project]_Ensemble_Models\"\n",
    "\n",
    "RUN_NAME = f\"{MODEL_NAME}\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb10e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (finetuning_pytorch.ipynbì™€ ë™ì¼)\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ë¦¬ë·° í…ìŠ¤íŠ¸ ë°ì´ì…‹ í´ë˜ìŠ¤\n",
    "    - BERT ëª¨ë¸ í›ˆë ¨/ì¶”ë¡ ì„ ìœ„í•œ PyTorch Dataset êµ¬í˜„\n",
    "    - í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§• ë° í…ì„œ ë³€í™˜ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        ë°ì´í„°ì…‹ ì´ˆê¸°í™”\n",
    "        \"\"\"\n",
    "        self.texts, self.labels, self.tokenizer, self.max_length = (\n",
    "            texts,\n",
    "            labels,\n",
    "            tokenizer,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"ë°ì´í„°ì…‹ í¬ê¸° ë°˜í™˜\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        íŠ¹ì • ì¸ë±ìŠ¤ì˜ ë°ì´í„° ì•„ì´í…œ ë°˜í™˜\n",
    "        \"\"\"\n",
    "        # í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì§• ë° íŒ¨ë”©\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,  # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ì‹œ ìë¥´ê¸°\n",
    "            padding=\"max_length\",  # ìµœëŒ€ ê¸¸ì´ê¹Œì§€ íŒ¨ë”©\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",  # PyTorch í…ì„œë¡œ ë°˜í™˜\n",
    "        )\n",
    "\n",
    "        # ê¸°ë³¸ ì•„ì´í…œ êµ¬ì„± (input_ids, attention_mask)\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        # labelsê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€ (train/validìš©)\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18efd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë¡œë“œ ì¤‘: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2\n",
      "âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_model(model_path):\n",
    "    \"\"\"í›ˆë ¨ëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        print(\"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ\")\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=4,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model, tokenizer = load_model(MODEL_PATH)\n",
    "\n",
    "if model is None or tokenizer is None:\n",
    "    print(\"âŒ ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03d9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "def predict_dataset(model, tokenizer, dataloader, device, dataset_name=\"Dataset\"):\n",
    "    \"\"\"ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"\\\\nğŸ“Š {dataset_name} ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Predicting {dataset_name}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            \n",
    "            # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # í™•ë¥  ê³„ì‚°\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            # ì˜ˆì¸¡ í´ë˜ìŠ¤\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "            # ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° (train/val ë°ì´í„°)\n",
    "            if \"labels\" in batch:\n",
    "                all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    print(f\"âœ… {dataset_name} ì˜ˆì¸¡ ì™„ë£Œ: {len(all_predictions):,}ê°œ\")\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": np.array(all_predictions),\n",
    "        \"probabilities\": np.array(all_probabilities),\n",
    "        \"labels\": np.array(all_labels) if all_labels else None\n",
    "    }\n",
    "\n",
    "print(\"âœ… ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf139a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "Train ë°ì´í„°: 129,630ê°œ\n",
      "Test ë°ì´í„°: 59,928ê°œ\n",
      "Val ë°ì´í„°: 6,823ê°œ\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "print(\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# Train ë°ì´í„° ë¡œë“œ\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "train_df = train_df[train_df[\"type\"] == \"original\"]\n",
    "print(f\"Train ë°ì´í„°: {len(train_df):,}ê°œ\")\n",
    "\n",
    "# Test ë°ì´í„° ë¡œë“œ\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"Test ë°ì´í„°: {len(test_df):,}ê°œ\")\n",
    "\n",
    "# Val ë°ì´í„° ë¡œë“œ (ì„±ëŠ¥ í‰ê°€ìš©)\n",
    "val_df = pd.read_csv(VAL_DATA_PATH)\n",
    "print(f\"Val ë°ì´í„°: {len(val_df):,}ê°œ\")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd4e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...\n",
      "âœ… ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "print(\"ğŸ”§ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...\")\n",
    "\n",
    "# ì„¤ì •\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "# Train ë°ì´í„°ì…‹\n",
    "train_dataset = ReviewDataset(\n",
    "    train_df[\"review\"],\n",
    "    train_df[\"label\"],\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Test ë°ì´í„°ì…‹\n",
    "test_dataset = ReviewDataset(\n",
    "    test_df[\"review\"],\n",
    "    None,  # Test ë°ì´í„°ëŠ” ë¼ë²¨ ì—†ìŒ\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Val ë°ì´í„°ì…‹\n",
    "val_dataset = ReviewDataset(\n",
    "    val_df[\"review\"],\n",
    "    val_df[\"label\"],\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# ë°ì´í„°ë¡œë” ìƒì„±\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea518be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œì‘...\n",
      "\\nğŸ“Š Test ì˜ˆì¸¡ ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e769b327b48433aa2672bb2f29d150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting Test:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test ì˜ˆì¸¡ ì™„ë£Œ: 59,928ê°œ\n",
      "\\nğŸ“Š Validation ì˜ˆì¸¡ ì‹œì‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6832d94c12848e890643f9569b46fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation ì˜ˆì¸¡ ì™„ë£Œ: 6,823ê°œ\n",
      "âœ… ëª¨ë“  ì˜ˆì¸¡ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"ğŸš€ ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œì‘...\")\n",
    "\n",
    "# Train ë°ì´í„° ì˜ˆì¸¡\n",
    "#train_results = predict_dataset(model, tokenizer, train_dataloader, device, \"Train\")\n",
    "\n",
    "# Test ë°ì´í„° ì˜ˆì¸¡\n",
    "test_results = predict_dataset(model, tokenizer, test_dataloader, device, \"Test\")\n",
    "\n",
    "# Val ë°ì´í„° ì˜ˆì¸¡ (ì„±ëŠ¥ í‰ê°€ìš©)\n",
    "val_results = predict_dataset(model, tokenizer, val_dataloader, device, \"Validation\")\n",
    "\n",
    "print(\"âœ… ëª¨ë“  ì˜ˆì¸¡ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718a76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ì„±ëŠ¥ í‰ê°€ (Train, Val ë°ì´í„°)\n",
    "# def evaluate_predictions(predictions, labels, dataset_name):\n",
    "#     \"\"\"ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "#     print(f\"\\\\nğŸ“Š {dataset_name} ì„±ëŠ¥ í‰ê°€:\")\n",
    "    \n",
    "#     accuracy = accuracy_score(labels, predictions)\n",
    "#     f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "#     print(f\"  ì •í™•ë„: {accuracy:.4f}\")\n",
    "#     print(f\"  F1 ì ìˆ˜: {f1:.4f}\")\n",
    "    \n",
    "#     # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n",
    "#     print(f\"\\\\n  í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "#     report = classification_report(labels, predictions, \n",
    "#                                  target_names=list(LABEL_MAPPING.values()),\n",
    "#                                  output_dict=True)\n",
    "    \n",
    "#     for i, class_name in LABEL_MAPPING.items():\n",
    "#         if str(i) in report:\n",
    "#             precision = report[str(i)][\"precision\"]\n",
    "#             recall = report[str(i)][\"recall\"]\n",
    "#             f1_score_class = report[str(i)][\"f1-score\"]\n",
    "#             support = report[str(i)][\"support\"]\n",
    "#             print(f\"    {class_name}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1_score_class:.3f}, Support={support}\")\n",
    "    \n",
    "#     return accuracy, f1\n",
    "\n",
    "# # Train ë°ì´í„° ì„±ëŠ¥ í‰ê°€\n",
    "# train_accuracy, train_f1 = evaluate_predictions(\n",
    "#     train_results[\"predictions\"], \n",
    "#     train_results[\"labels\"], \n",
    "#     \"Train\"\n",
    "# )\n",
    "\n",
    "# # Val ë°ì´í„° ì„±ëŠ¥ í‰ê°€\n",
    "# val_accuracy, val_f1 = evaluate_predictions(\n",
    "#     val_results[\"predictions\"], \n",
    "#     val_results[\"labels\"], \n",
    "#     \"Validation\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102638eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nğŸ“ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameì— ì¶”ê°€ ì¤‘...\n",
      "âœ… ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameì— ì¶”ê°€\n",
    "print(\"\\\\nğŸ“ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameì— ì¶”ê°€ ì¤‘...\")\n",
    "\n",
    "# # Train ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€\n",
    "# train_df[\"predicted_label\"] = train_results[\"predictions\"]\n",
    "# train_df[\"predicted_class\"] = train_df[\"predicted_label\"]\n",
    "\n",
    "# # ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶”ê°€\n",
    "# for i in range(4):\n",
    "#     train_df[f\"prob_class_{i}\"] = train_results[\"probabilities\"][:, i]\n",
    "\n",
    "# Test ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€\n",
    "test_df[\"pred\"] = test_results[\"predictions\"]\n",
    "\n",
    "\n",
    "# ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶”ê°€\n",
    "for i in range(4):\n",
    "    test_df[f\"prob_class_{i}\"] = test_results[\"probabilities\"][:, i]\n",
    "\n",
    "# Val ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€\n",
    "# val_df[\"pred\"] = val_results[\"predictions\"]\n",
    "\n",
    "\n",
    "# # ê° í´ë˜ìŠ¤ë³„ í™•ë¥  ì¶”ê°€\n",
    "# for i in range(4):\n",
    "#     val_df[f\"prob_class_{i}\"] = val_results[\"probabilities\"][:, i]\n",
    "\n",
    "print(\"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d113c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV íŒŒì¼ ì €ì¥\n",
    "print(\"\\\\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "# Train ë°ì´í„° ì €ì¥\n",
    "# train_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_train_predictions.csv\")\n",
    "# train_df.to_csv(train_output_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"âœ… Train ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {train_output_path}\")\n",
    "\n",
    "# Test ë°ì´í„° ì €ì¥\n",
    "test_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_test_predictions.csv\")\n",
    "test_df.to_csv(test_output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"âœ… Test ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {test_output_path}\")\n",
    "\n",
    "# # Val ë°ì´í„° ì €ì¥\n",
    "# val_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_val_predictions.csv\")\n",
    "# val_df.to_csv(val_output_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"âœ… Val ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {val_output_path}\")\n",
    "\n",
    "# ìš”ì•½ í†µê³„ ì €ì¥\n",
    "# summary_stats = {\n",
    "#     \"dataset\": [\"Train\", \"Validation\"],\n",
    "#     \"accuracy\": [train_accuracy, val_accuracy],\n",
    "#     \"f1_score\": [train_f1, val_f1],\n",
    "#     \"total_samples\": [len(train_df), len(val_df)]\n",
    "# }\n",
    "\n",
    "# summary_df = pd.DataFrame(summary_stats)\n",
    "# summary_path = os.path.join(OUTPUT_DIR, \"prediction_summary.csv\")\n",
    "# summary_df.to_csv(summary_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"âœ… ìš”ì•½ í†µê³„ ì €ì¥: {summary_path}\")\n",
    "\n",
    "# print(\"\\\\nğŸ‰ ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
