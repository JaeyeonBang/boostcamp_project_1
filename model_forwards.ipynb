{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99697bac",
   "metadata": {},
   "source": [
    "# 모델 예측 및 결과 저장\n",
    "\n",
    "이 노트북은 훈련된 모델을 사용하여 train data와 test data에 대한 예측을 수행하고 결과를 CSV 파일로 저장합니다.\n",
    "\n",
    "## 주요 기능\n",
    "- 훈련된 모델 로드\n",
    "- Train data와 Test data에 대한 예측 수행\n",
    "- 예측 결과를 CSV 파일로 저장\n",
    "- 예측 성능 분석 및 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636f74ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "# Library Import\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f7c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디바이스: cuda\n",
      "GPU 개수: 1\n",
      "   GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"디바이스: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"⚠️  CUDA 사용 불가 - CPU로 추론 진행\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "TIMESTAMP = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b2c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 설정 완료\n",
      "모델 경로: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2\n",
      "출력 디렉토리: ./predictions\n"
     ]
    }
   ],
   "source": [
    "# 설정\n",
    "MODEL_FOLDER = \"./Final_Models/original\"\n",
    "MODEL_NAME = \"/data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_05-34-33_RANDOM_42_final_training_2025-10-30_09-07-58_RANDOM_42_epoch_3\"\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER, MODEL_NAME)  # 훈련된 모델 경로\n",
    "\n",
    "TRAIN_DATA_PATH = \"/data/ephemeral/home/code/data/train_final_augX3.csv\"\n",
    "TEST_DATA_PATH = \"/data/ephemeral/home/code/data/test_processed.csv\"\n",
    "VAL_DATA_PATH = \"/data/ephemeral/home/code/data/val_final.csv\"\n",
    "\n",
    "# 출력 경로\n",
    "OUTPUT_DIR = \"./predictions\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 클래스 라벨 매핑\n",
    "LABEL_MAPPING = {0: \"매우 부정\", 1: \"부정\", 2: \"긍정\", 3: \"매우 긍정\"}\n",
    "REVERSE_LABEL_MAPPING = {v: k for k, v in LABEL_MAPPING.items()}\n",
    "\n",
    "print(\"✅ 설정 완료\")\n",
    "print(f\"모델 경로: {MODEL_PATH}\")\n",
    "print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe11d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = f\"[domain_project]_Ensemble_Models\"\n",
    "\n",
    "RUN_NAME = f\"{MODEL_NAME}\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb10e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터셋 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 클래스 정의 (finetuning_pytorch.ipynb와 동일)\n",
    "class ReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    리뷰 텍스트 데이셋 클래스\n",
    "    - BERT 모델 훈련/추론을 위한 PyTorch Dataset 구현\n",
    "    - 텍스트 토크나이징 및 텐서 변환 처리\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        데이터셋 초기화\n",
    "        \"\"\"\n",
    "        self.texts, self.labels, self.tokenizer, self.max_length = (\n",
    "            texts,\n",
    "            labels,\n",
    "            tokenizer,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋 크기 반환\"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        특정 인덱스의 데이터 아이템 반환\n",
    "        \"\"\"\n",
    "        # 텍스트 토크나이징 및 패딩\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts.iloc[idx]),\n",
    "            truncation=True,  # 최대 길이 초과시 자르기\n",
    "            padding=\"max_length\",  # 최대 길이까지 패딩\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",  # PyTorch 텐서로 반환\n",
    "        )\n",
    "\n",
    "        # 기본 아이템 구성 (input_ids, attention_mask)\n",
    "        item = {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        # labels가 None이 아닌 경우에만 추가 (train/valid용)\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n",
    "\n",
    "print(\"✅ 데이터셋 클래스 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18efd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 중: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2\n",
      "✅ 토크나이저 로드 완료\n",
      "✅ 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드 함수\n",
    "def load_model(model_path):\n",
    "    \"\"\"훈련된 모델과 토크나이저를 로드하는 함수\"\"\"\n",
    "    print(f\"모델 로드 중: {model_path}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ 모델 경로가 존재하지 않습니다: {model_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # 토크나이저 로드\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        print(\"✅ 토크나이저 로드 완료\")\n",
    "        \n",
    "        # 모델 로드\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=4,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        print(\"✅ 모델 로드 완료\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 로드 실패: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# 모델 로드\n",
    "model, tokenizer = load_model(MODEL_PATH)\n",
    "\n",
    "if model is None or tokenizer is None:\n",
    "    print(\"❌ 모델 로드에 실패했습니다. 프로그램을 종료합니다.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03d9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 예측 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 예측 함수\n",
    "def predict_dataset(model, tokenizer, dataloader, device, dataset_name=\"Dataset\"):\n",
    "    \"\"\"데이터셋에 대한 예측을 수행하는 함수\"\"\"\n",
    "    print(f\"\\\\n📊 {dataset_name} 예측 시작...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Predicting {dataset_name}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            \n",
    "            # 예측 수행\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # 확률 계산\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            # 예측 클래스\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            \n",
    "            # 라벨이 있는 경우 (train/val 데이터)\n",
    "            if \"labels\" in batch:\n",
    "                all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "    \n",
    "    print(f\"✅ {dataset_name} 예측 완료: {len(all_predictions):,}개\")\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": np.array(all_predictions),\n",
    "        \"probabilities\": np.array(all_probabilities),\n",
    "        \"labels\": np.array(all_labels) if all_labels else None\n",
    "    }\n",
    "\n",
    "print(\"✅ 예측 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf139a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 데이터 로드 중...\n",
      "Train 데이터: 129,630개\n",
      "Test 데이터: 59,928개\n",
      "Val 데이터: 6,823개\n",
      "✅ 데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "print(\"📂 데이터 로드 중...\")\n",
    "\n",
    "# Train 데이터 로드\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "train_df = train_df[train_df[\"type\"] == \"original\"]\n",
    "print(f\"Train 데이터: {len(train_df):,}개\")\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"Test 데이터: {len(test_df):,}개\")\n",
    "\n",
    "# Val 데이터 로드 (성능 평가용)\n",
    "val_df = pd.read_csv(VAL_DATA_PATH)\n",
    "print(f\"Val 데이터: {len(val_df):,}개\")\n",
    "\n",
    "print(\"✅ 데이터 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd4e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 데이터셋 및 데이터로더 생성 중...\n",
      "✅ 데이터셋 및 데이터로더 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "print(\"🔧 데이터셋 및 데이터로더 생성 중...\")\n",
    "\n",
    "# 설정\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "# Train 데이터셋\n",
    "train_dataset = ReviewDataset(\n",
    "    train_df[\"review\"],\n",
    "    train_df[\"label\"],\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Test 데이터셋\n",
    "test_dataset = ReviewDataset(\n",
    "    test_df[\"review\"],\n",
    "    None,  # Test 데이터는 라벨 없음\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Val 데이터셋\n",
    "val_dataset = ReviewDataset(\n",
    "    val_df[\"review\"],\n",
    "    val_df[\"label\"],\n",
    "    tokenizer,\n",
    "    MAX_LENGTH\n",
    ")\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터셋 및 데이터로더 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea518be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 예측 수행 시작...\n",
      "\\n📊 Test 예측 시작...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e769b327b48433aa2672bb2f29d150e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting Test:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test 예측 완료: 59,928개\n",
      "\\n📊 Validation 예측 시작...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6832d94c12848e890643f9569b46fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 예측 완료: 6,823개\n",
      "✅ 모든 예측 완료!\n"
     ]
    }
   ],
   "source": [
    "# 예측 수행\n",
    "print(\"🚀 예측 수행 시작...\")\n",
    "\n",
    "# Train 데이터 예측\n",
    "#train_results = predict_dataset(model, tokenizer, train_dataloader, device, \"Train\")\n",
    "\n",
    "# Test 데이터 예측\n",
    "test_results = predict_dataset(model, tokenizer, test_dataloader, device, \"Test\")\n",
    "\n",
    "# Val 데이터 예측 (성능 평가용)\n",
    "val_results = predict_dataset(model, tokenizer, val_dataloader, device, \"Validation\")\n",
    "\n",
    "print(\"✅ 모든 예측 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718a76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 성능 평가 (Train, Val 데이터)\n",
    "# def evaluate_predictions(predictions, labels, dataset_name):\n",
    "#     \"\"\"예측 결과를 평가하는 함수\"\"\"\n",
    "#     print(f\"\\\\n📊 {dataset_name} 성능 평가:\")\n",
    "    \n",
    "#     accuracy = accuracy_score(labels, predictions)\n",
    "#     f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    \n",
    "#     print(f\"  정확도: {accuracy:.4f}\")\n",
    "#     print(f\"  F1 점수: {f1:.4f}\")\n",
    "    \n",
    "#     # 클래스별 성능\n",
    "#     print(f\"\\\\n  클래스별 성능:\")\n",
    "#     report = classification_report(labels, predictions, \n",
    "#                                  target_names=list(LABEL_MAPPING.values()),\n",
    "#                                  output_dict=True)\n",
    "    \n",
    "#     for i, class_name in LABEL_MAPPING.items():\n",
    "#         if str(i) in report:\n",
    "#             precision = report[str(i)][\"precision\"]\n",
    "#             recall = report[str(i)][\"recall\"]\n",
    "#             f1_score_class = report[str(i)][\"f1-score\"]\n",
    "#             support = report[str(i)][\"support\"]\n",
    "#             print(f\"    {class_name}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1_score_class:.3f}, Support={support}\")\n",
    "    \n",
    "#     return accuracy, f1\n",
    "\n",
    "# # Train 데이터 성능 평가\n",
    "# train_accuracy, train_f1 = evaluate_predictions(\n",
    "#     train_results[\"predictions\"], \n",
    "#     train_results[\"labels\"], \n",
    "#     \"Train\"\n",
    "# )\n",
    "\n",
    "# # Val 데이터 성능 평가\n",
    "# val_accuracy, val_f1 = evaluate_predictions(\n",
    "#     val_results[\"predictions\"], \n",
    "#     val_results[\"labels\"], \n",
    "#     \"Validation\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102638eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n📝 예측 결과를 DataFrame에 추가 중...\n",
      "✅ 예측 결과 추가 완료\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 DataFrame에 추가\n",
    "print(\"\\\\n📝 예측 결과를 DataFrame에 추가 중...\")\n",
    "\n",
    "# # Train 데이터에 예측 결과 추가\n",
    "# train_df[\"predicted_label\"] = train_results[\"predictions\"]\n",
    "# train_df[\"predicted_class\"] = train_df[\"predicted_label\"]\n",
    "\n",
    "# # 각 클래스별 확률 추가\n",
    "# for i in range(4):\n",
    "#     train_df[f\"prob_class_{i}\"] = train_results[\"probabilities\"][:, i]\n",
    "\n",
    "# Test 데이터에 예측 결과 추가\n",
    "test_df[\"pred\"] = test_results[\"predictions\"]\n",
    "\n",
    "\n",
    "# 각 클래스별 확률 추가\n",
    "for i in range(4):\n",
    "    test_df[f\"prob_class_{i}\"] = test_results[\"probabilities\"][:, i]\n",
    "\n",
    "# Val 데이터에 예측 결과 추가\n",
    "# val_df[\"pred\"] = val_results[\"predictions\"]\n",
    "\n",
    "\n",
    "# # 각 클래스별 확률 추가\n",
    "# for i in range(4):\n",
    "#     val_df[f\"prob_class_{i}\"] = val_results[\"probabilities\"][:, i]\n",
    "\n",
    "print(\"✅ 예측 결과 추가 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32d113c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n💾 CSV 파일 저장 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test 예측 결과 저장: /data/ephemeral/home/code/Final_Models/original/TAPT_monologg_koelectra-base-v3-discriminator_augX3_best_discriminator_1028_final_training_2025-10-30_07-21-18_RANDOM_42_epoch_2_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 저장\n",
    "print(\"\\\\n💾 CSV 파일 저장 중...\")\n",
    "\n",
    "# Train 데이터 저장\n",
    "# train_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_train_predictions.csv\")\n",
    "# train_df.to_csv(train_output_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"✅ Train 예측 결과 저장: {train_output_path}\")\n",
    "\n",
    "# Test 데이터 저장\n",
    "test_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_test_predictions.csv\")\n",
    "test_df.to_csv(test_output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Test 예측 결과 저장: {test_output_path}\")\n",
    "\n",
    "# # Val 데이터 저장\n",
    "# val_output_path = os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_val_predictions.csv\")\n",
    "# val_df.to_csv(val_output_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"✅ Val 예측 결과 저장: {val_output_path}\")\n",
    "\n",
    "# 요약 통계 저장\n",
    "# summary_stats = {\n",
    "#     \"dataset\": [\"Train\", \"Validation\"],\n",
    "#     \"accuracy\": [train_accuracy, val_accuracy],\n",
    "#     \"f1_score\": [train_f1, val_f1],\n",
    "#     \"total_samples\": [len(train_df), len(val_df)]\n",
    "# }\n",
    "\n",
    "# summary_df = pd.DataFrame(summary_stats)\n",
    "# summary_path = os.path.join(OUTPUT_DIR, \"prediction_summary.csv\")\n",
    "# summary_df.to_csv(summary_path, index=False, encoding=\"utf-8\")\n",
    "# print(f\"✅ 요약 통계 저장: {summary_path}\")\n",
    "\n",
    "# print(\"\\\\n🎉 모든 파일 저장 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
